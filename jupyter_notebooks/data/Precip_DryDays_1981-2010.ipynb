{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precip Compare: Dry Days, 1981-2011"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the dry day spell length distributions and samples among the three data sets for the period 1981-2011.\n",
    "\n",
    "This climate period has three data sets\n",
    "\n",
    "1. PRISM (actual data)\n",
    "2. LOCA (downscaled GCM results)\n",
    "3. BCCA (downscaled GCM results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative binomial distributions have been fit to all of these data sets using R in separate Jupyter notebooks. The purpose of this notebook is to compare the fitted distributions and samples to see how different they are from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats as sstats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters, primarily input file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRISM_IN = r'\\\\augustine.space.swri.edu\\jdrive\\Groundwater\\R8937_Stochastic_CC_Rech' \\\n",
    "           r'arge\\Data\\JNotes\\Processed\\PRISM\\DryDays_1981-2010.pickle'\n",
    "CMIP5_IN = r'\\\\augustine.space.swri.edu\\jdrive\\Groundwater\\R8937_Stochastic_CC_Rech' \\\n",
    "           r'arge\\Data\\JNotes\\Processed\\CMIP5\\DryDays_1981-2010.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP5_XLSX = r'\\\\augustine.space.swri.edu\\jdrive\\Groundwater\\R8937_Stochastic_CC_Recharge\\Data\\JN' \\\n",
    "             r'otes\\Processed\\CMIP5\\CMIP5_1981_DryDays\\CMIP5_Dry_RSummary_1981-2010.xlsx'\n",
    "LOCA_SHT = r'LOCA_Dist_Properties'\n",
    "BCCA_SHT = r'BCCA_Dist_Properties'\n",
    "PRISM_XLSX = r'\\\\augustine.space.swri.edu\\jdrive\\Groundwater\\R8937_Stochastic_CC_Recharge\\Data\\JN' \\\n",
    "             r'otes\\Processed\\PRISM\\PRISM_DryDays\\PRISM_Dry_RSummary.xlsx'\n",
    "PRISM_SHT = r'Dist_Properties'\n",
    "HDRS = [ \"Month\", #0\n",
    "         \"Sample Mean (mu)\", #1\n",
    "         \"Sample Size (r)\", #2\n",
    "         \"Sample Prob (p)\", #3\n",
    "         \"FitDist Mean (mu)\", #4\n",
    "         \"FitDist Size (r)\", #5\n",
    "         \"p-value\", #6\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = r'\\\\augustine.space.swri.edu\\jdrive\\Groundwater\\R8937_Stochastic_CC_Recharge\\Data\\JN' \\\n",
    "          r'otes\\Processed\\Precip_Compare_1981-2010'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCA_GRID_END = 168       # the last LOCA grid cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the spreadsheets that have the fitted distribution parameters for the negative binomial distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRDistDF = pd.read_excel( PRISM_XLSX, sheet_name='Dist_Properties', header=None,\n",
    "                          index_col=0, names=HDRS, skiprows=[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Sample Mean (mu)</th>\n",
       "      <th>Sample Size (r)</th>\n",
       "      <th>Sample Prob (p)</th>\n",
       "      <th>FitDist Mean (mu)</th>\n",
       "      <th>FitDist Size (r)</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.667023</td>\n",
       "      <td>1.172800</td>\n",
       "      <td>0.137661</td>\n",
       "      <td>8.667270</td>\n",
       "      <td>1.383612</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8.246318</td>\n",
       "      <td>1.082622</td>\n",
       "      <td>0.149267</td>\n",
       "      <td>8.248172</td>\n",
       "      <td>1.447199</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8.187301</td>\n",
       "      <td>1.243559</td>\n",
       "      <td>0.175668</td>\n",
       "      <td>8.187292</td>\n",
       "      <td>1.744746</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.712354</td>\n",
       "      <td>1.381129</td>\n",
       "      <td>0.201979</td>\n",
       "      <td>7.714156</td>\n",
       "      <td>1.952456</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6.137622</td>\n",
       "      <td>1.216465</td>\n",
       "      <td>0.215061</td>\n",
       "      <td>6.138520</td>\n",
       "      <td>1.681859</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( HTML( PRDistDF.head().to_html() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LODistDF = pd.read_excel( CMIP5_XLSX, sheet_name=LOCA_SHT, header=None,\n",
    "                          index_col=0, names=HDRS, skiprows=[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Sample Mean (mu)</th>\n",
       "      <th>Sample Size (r)</th>\n",
       "      <th>Sample Prob (p)</th>\n",
       "      <th>FitDist Mean (mu)</th>\n",
       "      <th>FitDist Size (r)</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.600758</td>\n",
       "      <td>1.185742</td>\n",
       "      <td>0.166103</td>\n",
       "      <td>7.601987</td>\n",
       "      <td>1.514231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.007583</td>\n",
       "      <td>1.110408</td>\n",
       "      <td>0.183309</td>\n",
       "      <td>7.007788</td>\n",
       "      <td>1.572926</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6.988409</td>\n",
       "      <td>1.295000</td>\n",
       "      <td>0.189987</td>\n",
       "      <td>6.987467</td>\n",
       "      <td>1.638900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.137130</td>\n",
       "      <td>1.561368</td>\n",
       "      <td>0.291048</td>\n",
       "      <td>5.137729</td>\n",
       "      <td>2.109202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>4.141581</td>\n",
       "      <td>1.231282</td>\n",
       "      <td>0.330456</td>\n",
       "      <td>4.141817</td>\n",
       "      <td>2.044214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( HTML( LODistDF.head().to_html() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCDistDF = pd.read_excel( CMIP5_XLSX, sheet_name=BCCA_SHT, header=None,\n",
    "                          index_col=0, names=HDRS, skiprows=[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Sample Mean (mu)</th>\n",
       "      <th>Sample Size (r)</th>\n",
       "      <th>Sample Prob (p)</th>\n",
       "      <th>FitDist Mean (mu)</th>\n",
       "      <th>FitDist Size (r)</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.232795</td>\n",
       "      <td>1.336154</td>\n",
       "      <td>0.263764</td>\n",
       "      <td>5.233172</td>\n",
       "      <td>1.874835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.758961</td>\n",
       "      <td>1.336110</td>\n",
       "      <td>0.295503</td>\n",
       "      <td>4.758978</td>\n",
       "      <td>1.996164</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.552056</td>\n",
       "      <td>1.477125</td>\n",
       "      <td>0.319712</td>\n",
       "      <td>4.552470</td>\n",
       "      <td>2.139504</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.528720</td>\n",
       "      <td>1.849420</td>\n",
       "      <td>0.441161</td>\n",
       "      <td>3.528137</td>\n",
       "      <td>2.785191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2.772238</td>\n",
       "      <td>2.210170</td>\n",
       "      <td>0.570102</td>\n",
       "      <td>2.772337</td>\n",
       "      <td>3.676495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( HTML( BCDistDF.head().to_html() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDRS.append( \"FitDist Prob (p)\" ) # 7\n",
    "HDRS.append( \"FitDist Var\" ) #8\n",
    "HDRS.append( \"FitDist Std\" ) #9\n",
    "HDRS.append( \"FitDist AltForm P\" ) #10\n",
    "HDRS.append( \"FitDist AltForm N\" ) #11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRDistDF[HDRS[7]] = ( PRDistDF[HDRS[5]] / ( PRDistDF[HDRS[5]] + PRDistDF[HDRS[4]] ))\n",
    "PRDistDF[HDRS[8]] = ( PRDistDF[HDRS[4]] + ( ( 1.0 / PRDistDF[HDRS[5]]) * (PRDistDF[HDRS[4]]**2.0) ) )\n",
    "PRDistDF[HDRS[9]] = np.sqrt( np.array( PRDistDF[HDRS[8]], dtype=np.float32 ) )\n",
    "PRDistDF[HDRS[10]] = 1.0 - ((PRDistDF[HDRS[8]] - PRDistDF[HDRS[4]]) / PRDistDF[HDRS[8]] )\n",
    "PRDistDF[HDRS[11]] = ( PRDistDF[HDRS[4]]**2.0 )/(PRDistDF[HDRS[8]] - PRDistDF[HDRS[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Sample Mean (mu)</th>\n",
       "      <th>Sample Size (r)</th>\n",
       "      <th>Sample Prob (p)</th>\n",
       "      <th>FitDist Mean (mu)</th>\n",
       "      <th>FitDist Size (r)</th>\n",
       "      <th>p-value</th>\n",
       "      <th>FitDist Prob (p)</th>\n",
       "      <th>FitDist Var</th>\n",
       "      <th>FitDist Std</th>\n",
       "      <th>FitDist AltForm P</th>\n",
       "      <th>FitDist AltForm N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.667023</td>\n",
       "      <td>1.172800</td>\n",
       "      <td>0.137661</td>\n",
       "      <td>8.667270</td>\n",
       "      <td>1.383612</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.137661</td>\n",
       "      <td>62.961064</td>\n",
       "      <td>7.934801</td>\n",
       "      <td>0.137661</td>\n",
       "      <td>1.383612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8.246318</td>\n",
       "      <td>1.082622</td>\n",
       "      <td>0.149267</td>\n",
       "      <td>8.248172</td>\n",
       "      <td>1.447199</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.149267</td>\n",
       "      <td>55.257839</td>\n",
       "      <td>7.433562</td>\n",
       "      <td>0.149267</td>\n",
       "      <td>1.447199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8.187301</td>\n",
       "      <td>1.243559</td>\n",
       "      <td>0.175668</td>\n",
       "      <td>8.187292</td>\n",
       "      <td>1.744746</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.175668</td>\n",
       "      <td>46.606499</td>\n",
       "      <td>6.826895</td>\n",
       "      <td>0.175668</td>\n",
       "      <td>1.744746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.712354</td>\n",
       "      <td>1.381129</td>\n",
       "      <td>0.201979</td>\n",
       "      <td>7.714156</td>\n",
       "      <td>1.952456</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.201979</td>\n",
       "      <td>38.192794</td>\n",
       "      <td>6.180032</td>\n",
       "      <td>0.201979</td>\n",
       "      <td>1.952456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6.137622</td>\n",
       "      <td>1.216465</td>\n",
       "      <td>0.215061</td>\n",
       "      <td>6.138520</td>\n",
       "      <td>1.681859</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.215061</td>\n",
       "      <td>28.543146</td>\n",
       "      <td>5.342578</td>\n",
       "      <td>0.215061</td>\n",
       "      <td>1.681859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6.979430</td>\n",
       "      <td>0.703247</td>\n",
       "      <td>0.141198</td>\n",
       "      <td>6.980845</td>\n",
       "      <td>1.147736</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.141198</td>\n",
       "      <td>49.440271</td>\n",
       "      <td>7.031377</td>\n",
       "      <td>0.141198</td>\n",
       "      <td>1.147736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>9.004230</td>\n",
       "      <td>0.998290</td>\n",
       "      <td>0.115956</td>\n",
       "      <td>9.004224</td>\n",
       "      <td>1.181042</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.115956</td>\n",
       "      <td>77.652144</td>\n",
       "      <td>8.812045</td>\n",
       "      <td>0.115956</td>\n",
       "      <td>1.181042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>6.787960</td>\n",
       "      <td>1.072274</td>\n",
       "      <td>0.191943</td>\n",
       "      <td>6.787059</td>\n",
       "      <td>1.612179</td>\n",
       "      <td>4.088234e-195</td>\n",
       "      <td>0.191943</td>\n",
       "      <td>35.359676</td>\n",
       "      <td>5.946400</td>\n",
       "      <td>0.191943</td>\n",
       "      <td>1.612179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>7.639352</td>\n",
       "      <td>0.971809</td>\n",
       "      <td>0.155058</td>\n",
       "      <td>7.640938</td>\n",
       "      <td>1.402213</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.155058</td>\n",
       "      <td>49.277930</td>\n",
       "      <td>7.019824</td>\n",
       "      <td>0.155058</td>\n",
       "      <td>1.402213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>9.825452</td>\n",
       "      <td>0.608974</td>\n",
       "      <td>0.090977</td>\n",
       "      <td>9.824798</td>\n",
       "      <td>0.983284</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.090977</td>\n",
       "      <td>107.992403</td>\n",
       "      <td>10.391939</td>\n",
       "      <td>0.090977</td>\n",
       "      <td>0.983284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>11.089027</td>\n",
       "      <td>1.031087</td>\n",
       "      <td>0.102578</td>\n",
       "      <td>11.090025</td>\n",
       "      <td>1.267619</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.102578</td>\n",
       "      <td>108.113399</td>\n",
       "      <td>10.397759</td>\n",
       "      <td>0.102578</td>\n",
       "      <td>1.267619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>11.275549</td>\n",
       "      <td>0.825546</td>\n",
       "      <td>0.087301</td>\n",
       "      <td>11.273808</td>\n",
       "      <td>1.078355</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.087301</td>\n",
       "      <td>129.137315</td>\n",
       "      <td>11.363860</td>\n",
       "      <td>0.087301</td>\n",
       "      <td>1.078355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( HTML( PRDistDF.to_html() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = sstats.nbinom( 1.38361241, 0.13766079 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(8.66726998), array(62.96106524))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rv.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LODistDF[HDRS[7]] = ( LODistDF[HDRS[5]] / ( LODistDF[HDRS[5]] + LODistDF[HDRS[4]] ))\n",
    "LODistDF[HDRS[8]] = ( LODistDF[HDRS[4]] + ( ( 1.0 / LODistDF[HDRS[5]]) * (LODistDF[HDRS[4]]**2.0) ) )\n",
    "LODistDF[HDRS[9]] = np.sqrt( np.array( LODistDF[HDRS[8]], dtype=np.float32 ) )\n",
    "LODistDF[HDRS[10]] = 1.0 - ((LODistDF[HDRS[8]] - LODistDF[HDRS[4]]) / LODistDF[HDRS[8]] )\n",
    "LODistDF[HDRS[11]] = ( LODistDF[HDRS[4]]**2.0 )/(LODistDF[HDRS[8]] - LODistDF[HDRS[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Sample Mean (mu)</th>\n",
       "      <th>Sample Size (r)</th>\n",
       "      <th>Sample Prob (p)</th>\n",
       "      <th>FitDist Mean (mu)</th>\n",
       "      <th>FitDist Size (r)</th>\n",
       "      <th>p-value</th>\n",
       "      <th>FitDist Prob (p)</th>\n",
       "      <th>FitDist Var</th>\n",
       "      <th>FitDist Std</th>\n",
       "      <th>FitDist AltForm P</th>\n",
       "      <th>FitDist AltForm N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.600758</td>\n",
       "      <td>1.185742</td>\n",
       "      <td>0.166103</td>\n",
       "      <td>7.601987</td>\n",
       "      <td>1.514231</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166103</td>\n",
       "      <td>45.766710</td>\n",
       "      <td>6.765110</td>\n",
       "      <td>0.166103</td>\n",
       "      <td>1.514231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.007583</td>\n",
       "      <td>1.110408</td>\n",
       "      <td>0.183309</td>\n",
       "      <td>7.007788</td>\n",
       "      <td>1.572926</td>\n",
       "      <td>0</td>\n",
       "      <td>0.183309</td>\n",
       "      <td>38.229278</td>\n",
       "      <td>6.182983</td>\n",
       "      <td>0.183309</td>\n",
       "      <td>1.572926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6.988409</td>\n",
       "      <td>1.295000</td>\n",
       "      <td>0.189987</td>\n",
       "      <td>6.987467</td>\n",
       "      <td>1.638900</td>\n",
       "      <td>0</td>\n",
       "      <td>0.189987</td>\n",
       "      <td>36.778601</td>\n",
       "      <td>6.064537</td>\n",
       "      <td>0.189987</td>\n",
       "      <td>1.638900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.137130</td>\n",
       "      <td>1.561368</td>\n",
       "      <td>0.291048</td>\n",
       "      <td>5.137729</td>\n",
       "      <td>2.109202</td>\n",
       "      <td>0</td>\n",
       "      <td>0.291048</td>\n",
       "      <td>17.652540</td>\n",
       "      <td>4.201493</td>\n",
       "      <td>0.291048</td>\n",
       "      <td>2.109202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>4.141581</td>\n",
       "      <td>1.231282</td>\n",
       "      <td>0.330456</td>\n",
       "      <td>4.141817</td>\n",
       "      <td>2.044214</td>\n",
       "      <td>0</td>\n",
       "      <td>0.330456</td>\n",
       "      <td>12.533622</td>\n",
       "      <td>3.540286</td>\n",
       "      <td>0.330456</td>\n",
       "      <td>2.044214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5.525916</td>\n",
       "      <td>0.746824</td>\n",
       "      <td>0.191004</td>\n",
       "      <td>5.525485</td>\n",
       "      <td>1.304567</td>\n",
       "      <td>0</td>\n",
       "      <td>0.191004</td>\n",
       "      <td>28.928646</td>\n",
       "      <td>5.378536</td>\n",
       "      <td>0.191004</td>\n",
       "      <td>1.304567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>6.813155</td>\n",
       "      <td>0.966848</td>\n",
       "      <td>0.164184</td>\n",
       "      <td>6.813245</td>\n",
       "      <td>1.338363</td>\n",
       "      <td>0</td>\n",
       "      <td>0.164184</td>\n",
       "      <td>41.497641</td>\n",
       "      <td>6.441866</td>\n",
       "      <td>0.164184</td>\n",
       "      <td>1.338363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>6.144145</td>\n",
       "      <td>1.257722</td>\n",
       "      <td>0.207095</td>\n",
       "      <td>6.145803</td>\n",
       "      <td>1.605190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.207095</td>\n",
       "      <td>29.676292</td>\n",
       "      <td>5.447595</td>\n",
       "      <td>0.207095</td>\n",
       "      <td>1.605190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5.095597</td>\n",
       "      <td>1.118345</td>\n",
       "      <td>0.248347</td>\n",
       "      <td>5.094812</td>\n",
       "      <td>1.683328</td>\n",
       "      <td>0</td>\n",
       "      <td>0.248347</td>\n",
       "      <td>20.514925</td>\n",
       "      <td>4.529340</td>\n",
       "      <td>0.248347</td>\n",
       "      <td>1.683328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>6.233228</td>\n",
       "      <td>0.951995</td>\n",
       "      <td>0.188842</td>\n",
       "      <td>6.234009</td>\n",
       "      <td>1.451311</td>\n",
       "      <td>0</td>\n",
       "      <td>0.188842</td>\n",
       "      <td>33.011770</td>\n",
       "      <td>5.745587</td>\n",
       "      <td>0.188842</td>\n",
       "      <td>1.451311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>6.536864</td>\n",
       "      <td>0.917107</td>\n",
       "      <td>0.177482</td>\n",
       "      <td>6.538020</td>\n",
       "      <td>1.410770</td>\n",
       "      <td>0</td>\n",
       "      <td>0.177482</td>\n",
       "      <td>36.837571</td>\n",
       "      <td>6.069396</td>\n",
       "      <td>0.177482</td>\n",
       "      <td>1.410770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>7.386455</td>\n",
       "      <td>1.013352</td>\n",
       "      <td>0.159314</td>\n",
       "      <td>7.386520</td>\n",
       "      <td>1.399783</td>\n",
       "      <td>0</td>\n",
       "      <td>0.159314</td>\n",
       "      <td>46.364464</td>\n",
       "      <td>6.809145</td>\n",
       "      <td>0.159314</td>\n",
       "      <td>1.399783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( HTML( LODistDF.to_html() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCDistDF[HDRS[7]] = ( BCDistDF[HDRS[5]] / ( BCDistDF[HDRS[5]] + BCDistDF[HDRS[4]] ))\n",
    "BCDistDF[HDRS[8]] = ( BCDistDF[HDRS[4]] + ( ( 1.0 / BCDistDF[HDRS[5]]) * (BCDistDF[HDRS[4]]**2.0) ) )\n",
    "BCDistDF[HDRS[9]] = np.sqrt( np.array( BCDistDF[HDRS[8]], dtype=np.float32 ) )\n",
    "BCDistDF[HDRS[10]] = 1.0 - ((BCDistDF[HDRS[8]] - BCDistDF[HDRS[4]]) / BCDistDF[HDRS[8]] )\n",
    "BCDistDF[HDRS[11]] = ( BCDistDF[HDRS[4]]**2.0 )/(BCDistDF[HDRS[8]] - BCDistDF[HDRS[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Sample Mean (mu)</th>\n",
       "      <th>Sample Size (r)</th>\n",
       "      <th>Sample Prob (p)</th>\n",
       "      <th>FitDist Mean (mu)</th>\n",
       "      <th>FitDist Size (r)</th>\n",
       "      <th>p-value</th>\n",
       "      <th>FitDist Prob (p)</th>\n",
       "      <th>FitDist Var</th>\n",
       "      <th>FitDist Std</th>\n",
       "      <th>FitDist AltForm P</th>\n",
       "      <th>FitDist AltForm N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.232795</td>\n",
       "      <td>1.336154</td>\n",
       "      <td>0.263764</td>\n",
       "      <td>5.233172</td>\n",
       "      <td>1.874835</td>\n",
       "      <td>0</td>\n",
       "      <td>0.263764</td>\n",
       "      <td>19.840368</td>\n",
       "      <td>4.454253</td>\n",
       "      <td>0.263764</td>\n",
       "      <td>1.874835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.758961</td>\n",
       "      <td>1.336110</td>\n",
       "      <td>0.295503</td>\n",
       "      <td>4.758978</td>\n",
       "      <td>1.996164</td>\n",
       "      <td>0</td>\n",
       "      <td>0.295503</td>\n",
       "      <td>16.104679</td>\n",
       "      <td>4.013063</td>\n",
       "      <td>0.295503</td>\n",
       "      <td>1.996164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.552056</td>\n",
       "      <td>1.477125</td>\n",
       "      <td>0.319712</td>\n",
       "      <td>4.552470</td>\n",
       "      <td>2.139504</td>\n",
       "      <td>0</td>\n",
       "      <td>0.319712</td>\n",
       "      <td>14.239289</td>\n",
       "      <td>3.773498</td>\n",
       "      <td>0.319712</td>\n",
       "      <td>2.139504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.528720</td>\n",
       "      <td>1.849420</td>\n",
       "      <td>0.441161</td>\n",
       "      <td>3.528137</td>\n",
       "      <td>2.785191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441161</td>\n",
       "      <td>7.997399</td>\n",
       "      <td>2.827967</td>\n",
       "      <td>0.441161</td>\n",
       "      <td>2.785191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2.772238</td>\n",
       "      <td>2.210170</td>\n",
       "      <td>0.570102</td>\n",
       "      <td>2.772337</td>\n",
       "      <td>3.676495</td>\n",
       "      <td>0</td>\n",
       "      <td>0.570102</td>\n",
       "      <td>4.862875</td>\n",
       "      <td>2.205193</td>\n",
       "      <td>0.570102</td>\n",
       "      <td>3.676495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>3.153229</td>\n",
       "      <td>1.629825</td>\n",
       "      <td>0.464570</td>\n",
       "      <td>3.153567</td>\n",
       "      <td>2.736221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464570</td>\n",
       "      <td>6.788138</td>\n",
       "      <td>2.605406</td>\n",
       "      <td>0.464570</td>\n",
       "      <td>2.736221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3.326397</td>\n",
       "      <td>1.668563</td>\n",
       "      <td>0.442866</td>\n",
       "      <td>3.326571</td>\n",
       "      <td>2.644290</td>\n",
       "      <td>0</td>\n",
       "      <td>0.442866</td>\n",
       "      <td>7.511465</td>\n",
       "      <td>2.740705</td>\n",
       "      <td>0.442866</td>\n",
       "      <td>2.644290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2.961173</td>\n",
       "      <td>2.194356</td>\n",
       "      <td>0.534924</td>\n",
       "      <td>2.960953</td>\n",
       "      <td>3.405646</td>\n",
       "      <td>0</td>\n",
       "      <td>0.534924</td>\n",
       "      <td>5.535279</td>\n",
       "      <td>2.352717</td>\n",
       "      <td>0.534924</td>\n",
       "      <td>3.405646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>3.225280</td>\n",
       "      <td>1.345049</td>\n",
       "      <td>0.427616</td>\n",
       "      <td>3.226003</td>\n",
       "      <td>2.410082</td>\n",
       "      <td>0</td>\n",
       "      <td>0.427616</td>\n",
       "      <td>7.544152</td>\n",
       "      <td>2.746662</td>\n",
       "      <td>0.427616</td>\n",
       "      <td>2.410082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>4.652360</td>\n",
       "      <td>1.156827</td>\n",
       "      <td>0.275202</td>\n",
       "      <td>4.652368</td>\n",
       "      <td>1.766480</td>\n",
       "      <td>0</td>\n",
       "      <td>0.275202</td>\n",
       "      <td>16.905281</td>\n",
       "      <td>4.111603</td>\n",
       "      <td>0.275202</td>\n",
       "      <td>1.766480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>5.412098</td>\n",
       "      <td>1.153981</td>\n",
       "      <td>0.240139</td>\n",
       "      <td>5.411843</td>\n",
       "      <td>1.710308</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240139</td>\n",
       "      <td>22.536272</td>\n",
       "      <td>4.747238</td>\n",
       "      <td>0.240139</td>\n",
       "      <td>1.710308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>5.595507</td>\n",
       "      <td>1.177020</td>\n",
       "      <td>0.234008</td>\n",
       "      <td>5.595613</td>\n",
       "      <td>1.709438</td>\n",
       "      <td>0</td>\n",
       "      <td>0.234008</td>\n",
       "      <td>23.912086</td>\n",
       "      <td>4.889998</td>\n",
       "      <td>0.234008</td>\n",
       "      <td>1.709438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( HTML( BCDistDF.to_html() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"DryDist_Compare_1981-2011.xlsx\" ) )\n",
    "with pd.ExcelWriter( OutFiler ) as writer:\n",
    "    PRDistDF.to_excel( writer, sheet_name=\"PRISM\", na_rep=str(np.nan), columns=HDRS,\n",
    "                       index=False )\n",
    "    LODistDF.to_excel( writer, sheet_name=\"LOCA\", na_rep=str(np.nan), columns=HDRS,\n",
    "                       index=False )\n",
    "    BCDistDF.to_excel( writer, sheet_name=\"BCCA\", na_rep=str(np.nan), columns=HDRS,\n",
    "                       index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Reduce DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrismDF = pd.read_pickle( PRISM_IN )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display( HTML( PrismDF.head().to_html() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanPRDF = PrismDF[PrismDF[\"Month\"] == 1].copy()\n",
    "FebPRDF = PrismDF[PrismDF[\"Month\"] == 2].copy()\n",
    "MarPRDF = PrismDF[PrismDF[\"Month\"] == 3].copy()\n",
    "AprPRDF = PrismDF[PrismDF[\"Month\"] == 4].copy()\n",
    "MayPRDF = PrismDF[PrismDF[\"Month\"] == 5].copy()\n",
    "JunPRDF = PrismDF[PrismDF[\"Month\"] == 6].copy()\n",
    "JulPRDF = PrismDF[PrismDF[\"Month\"] == 7].copy()\n",
    "AugPRDF = PrismDF[PrismDF[\"Month\"] == 8].copy()\n",
    "SepPRDF = PrismDF[PrismDF[\"Month\"] == 9].copy()\n",
    "OctPRDF = PrismDF[PrismDF[\"Month\"] == 10].copy()\n",
    "NovPRDF = PrismDF[PrismDF[\"Month\"] == 11].copy()\n",
    "DecPRDF = PrismDF[PrismDF[\"Month\"] == 12].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del PrismDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CmipDF = pd.read_pickle( CMIP5_IN )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display( HTML( CmipDF.head().to_html() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to split CMIP5 data by grid id and then by month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExGridID = lambda MID: int( MID.split(\"_\")[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CmipDF[\"Grid_Id\"] = CmipDF.apply( lambda row: ExGridID(row[\"MGrid_Id\"]), axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display( HTML( CmipDF.head().to_html() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display( HTML( CmipDF.tail().to_html() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanLODF = CmipDF[(CmipDF[\"Month\"] == 1) & (CmipDF[\"Grid_Id\"] <= LOCA_GRID_END)].copy()\n",
    "FebLODF = CmipDF[(CmipDF[\"Month\"] == 2) & (CmipDF[\"Grid_Id\"] <= LOCA_GRID_END)].copy()\n",
    "MarLODF = CmipDF[(CmipDF[\"Month\"] == 3) & (CmipDF[\"Grid_Id\"] <= LOCA_GRID_END)].copy()\n",
    "AprLODF = CmipDF[(CmipDF[\"Month\"] == 4) & (CmipDF[\"Grid_Id\"] <= LOCA_GRID_END)].copy()\n",
    "MayLODF = CmipDF[(CmipDF[\"Month\"] == 5) & (CmipDF[\"Grid_Id\"] <= LOCA_GRID_END)].copy()\n",
    "JunLODF = CmipDF[(CmipDF[\"Month\"] == 6) & (CmipDF[\"Grid_Id\"] <= LOCA_GRID_END)].copy()\n",
    "JulLODF = CmipDF[(CmipDF[\"Month\"] == 7) & (CmipDF[\"Grid_Id\"] <= LOCA_GRID_END)].copy()\n",
    "AugLODF = CmipDF[(CmipDF[\"Month\"] == 8) & (CmipDF[\"Grid_Id\"] <= LOCA_GRID_END)].copy()\n",
    "SepLODF = CmipDF[(CmipDF[\"Month\"] == 9) & (CmipDF[\"Grid_Id\"] <= LOCA_GRID_END)].copy()\n",
    "OctLODF = CmipDF[(CmipDF[\"Month\"] == 10) & (CmipDF[\"Grid_Id\"] <= LOCA_GRID_END)].copy()\n",
    "NovLODF = CmipDF[(CmipDF[\"Month\"] == 11) & (CmipDF[\"Grid_Id\"] <= LOCA_GRID_END)].copy()\n",
    "DecLODF = CmipDF[(CmipDF[\"Month\"] == 12) & (CmipDF[\"Grid_Id\"] <= LOCA_GRID_END)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanBCDF = CmipDF[(CmipDF[\"Month\"] == 1) & (CmipDF[\"Grid_Id\"] > LOCA_GRID_END)].copy()\n",
    "FebBCDF = CmipDF[(CmipDF[\"Month\"] == 2) & (CmipDF[\"Grid_Id\"] > LOCA_GRID_END)].copy()\n",
    "MarBCDF = CmipDF[(CmipDF[\"Month\"] == 3) & (CmipDF[\"Grid_Id\"] > LOCA_GRID_END)].copy()\n",
    "AprBCDF = CmipDF[(CmipDF[\"Month\"] == 4) & (CmipDF[\"Grid_Id\"] > LOCA_GRID_END)].copy()\n",
    "MayBCDF = CmipDF[(CmipDF[\"Month\"] == 5) & (CmipDF[\"Grid_Id\"] > LOCA_GRID_END)].copy()\n",
    "JunBCDF = CmipDF[(CmipDF[\"Month\"] == 6) & (CmipDF[\"Grid_Id\"] > LOCA_GRID_END)].copy()\n",
    "JulBCDF = CmipDF[(CmipDF[\"Month\"] == 7) & (CmipDF[\"Grid_Id\"] > LOCA_GRID_END)].copy()\n",
    "AugBCDF = CmipDF[(CmipDF[\"Month\"] == 8) & (CmipDF[\"Grid_Id\"] > LOCA_GRID_END)].copy()\n",
    "SepBCDF = CmipDF[(CmipDF[\"Month\"] == 9) & (CmipDF[\"Grid_Id\"] > LOCA_GRID_END)].copy()\n",
    "OctBCDF = CmipDF[(CmipDF[\"Month\"] == 10) & (CmipDF[\"Grid_Id\"] > LOCA_GRID_END)].copy()\n",
    "NovBCDF = CmipDF[(CmipDF[\"Month\"] == 11) & (CmipDF[\"Grid_Id\"] > LOCA_GRID_END)].copy()\n",
    "DecBCDF = CmipDF[(CmipDF[\"Month\"] == 12) & (CmipDF[\"Grid_Id\"] > LOCA_GRID_END)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del CmipDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons by Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPRMean = list()\n",
    "SPRMeanMinCI = list()\n",
    "SPRMeanMaxCI = list()\n",
    "SPRVar = list()\n",
    "SPRVarMinCI = list()\n",
    "SPRVarMaxCI = list()\n",
    "SPRStd = list()\n",
    "SPRStdMinCI = list()\n",
    "SPRStdMaxCI = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLOMean = list()\n",
    "SLOMeanMinCI = list()\n",
    "SLOMeanMaxCI = list()\n",
    "SLOVar = list()\n",
    "SLOVarMinCI = list()\n",
    "SLOVarMaxCI = list()\n",
    "SLOStd = list()\n",
    "SLOStdMinCI = list()\n",
    "SLOStdMaxCI = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBCMean = list()\n",
    "SBCMeanMinCI = list()\n",
    "SBCMeanMaxCI = list()\n",
    "SBCVar = list()\n",
    "SBCVarMinCI = list()\n",
    "SBCVarMaxCI = list()\n",
    "SBCStd = list()\n",
    "SBCStdMinCI = list()\n",
    "SBCStdMaxCI = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CompQs = [ round(x * 0.05, 2) for x in range(21) ]\n",
    "nCompQs = np.array( CompQs, dtype=np.float32 )\n",
    "nCompQs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some theoretical or fit parameters to use later for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanNum = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRConvP = PRDistDF.at[JanNum , HDRS[10]]\n",
    "PRConvR = PRDistDF.at[JanNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOConvP = LODistDF.at[JanNum , HDRS[10]]\n",
    "LOConvR = LODistDF.at[JanNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCConvP = BCDistDF.at[JanNum , HDRS[10]]\n",
    "BCConvR = BCDistDF.at[JanNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian estimates of confidence intervals for mean, variance, and standard deviation of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanPrBSCI = sstats.bayes_mvs( np.array( JanPRDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanPrBSCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanPrBSCI[0][0], JanPrBSCI[0][1][0], JanPrBSCI[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPRMean.append( JanPrBSCI[0][0] )\n",
    "SPRMeanMinCI.append( JanPrBSCI[0][1][0] )\n",
    "SPRMeanMaxCI.append( JanPrBSCI[0][1][1] )\n",
    "SPRVar.append( JanPrBSCI[1][0] )\n",
    "SPRVarMinCI.append( JanPrBSCI[1][1][0] )\n",
    "SPRVarMaxCI.append( JanPrBSCI[1][1][1] )\n",
    "SPRStd.append( JanPrBSCI[2][0] )\n",
    "SPRStdMinCI.append( JanPrBSCI[2][1][0] )\n",
    "SPRStdMaxCI.append( JanPrBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanLOBSCI = sstats.bayes_mvs( np.array( JanLODF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLOMean.append( JanLOBSCI[0][0] )\n",
    "SLOMeanMinCI.append( JanLOBSCI[0][1][0] )\n",
    "SLOMeanMaxCI.append( JanLOBSCI[0][1][1] )\n",
    "SLOVar.append( JanLOBSCI[1][0] )\n",
    "SLOVarMinCI.append( JanLOBSCI[1][1][0] )\n",
    "SLOVarMaxCI.append( JanLOBSCI[1][1][1] )\n",
    "SLOStd.append( JanLOBSCI[2][0] )\n",
    "SLOStdMinCI.append( JanLOBSCI[2][1][0] )\n",
    "SLOStdMaxCI.append( JanLOBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanBCBSCI = sstats.bayes_mvs( np.array( JanBCDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBCMean.append( JanBCBSCI[0][0] )\n",
    "SBCMeanMinCI.append( JanBCBSCI[0][1][0] )\n",
    "SBCMeanMaxCI.append( JanBCBSCI[0][1][1] )\n",
    "SBCVar.append( JanBCBSCI[1][0] )\n",
    "SBCVarMinCI.append( JanBCBSCI[1][1][0] )\n",
    "SBCVarMaxCI.append( JanBCBSCI[1][1][1] )\n",
    "SBCStd.append( JanBCBSCI[2][0] )\n",
    "SBCStdMinCI.append( JanBCBSCI[2][1][0] )\n",
    "SBCStdMaxCI.append( JanBCBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-Test for the means of two independent samples. Two-sided test for the null hypothesis that 2 independent samples hae identical average values. Test assumes that the populations have identical variances.\n",
    "\n",
    "If we observe a large p-value, for example larger than 0.05 or 0.1, then we cannot reject the null hypothesis of identical average scores. If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of equal averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanTTPRtoLO = sstats.ttest_ind( np.array( JanPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( JanLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanTTPRtoLOPval = JanTTPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same population is: %g\" % JanTTPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanTTPRtoBC = sstats.ttest_ind( np.array( JanPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( JanBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanTTPRtoBCPval = JanTTPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same population is: %g\" % JanTTPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanTTLOtoBC = sstats.ttest_ind( np.array( JanLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( JanBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanTTLOtoBCPval = JanTTLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same population is: %g\" % JanTTLOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mann-Whitney Rank Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonparametric test of the null hypothesis that it is equally likely that a randomly selected value from one sample will be less than or greater than a randomly selected value from a second sample. This test can be used to investigate whether two independent samples were selected from populations having the same distribution.\n",
    "\n",
    "Null hypothesis, $H_{0}$, is that the distributions of both populations are equal.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of being from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanMWUPRtoLO = sstats.mannwhitneyu( np.array( JanPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( JanLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanMWUPRtoLOPval = JanMWUPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same distribution is: %g\" % JanMWUPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanMWUPRtoBC = sstats.mannwhitneyu( np.array( JanPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( JanBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanMWUPRtoBCPval = JanMWUPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same distribution is: %g\" % JanMWUPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanMWULOtoBC = sstats.mannwhitneyu( np.array( JanLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( JanBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanMWULOtoBCPval = JanMWULOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same distribution is: %g\" % JanMWULOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kruskal-Wallis Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kruskal-Wallis H-test tests the null hypothesis that the population median of all of the groups are equal. It is a non-parametric version of ANOVA. The test works on 2 or more independent samples, which may have different sizes. Note that rejecting the null hypothesis does not indicate which of the groups differs.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of the same population median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanKWPRtoLO = sstats.kruskal( np.array( JanPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( JanLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanKWPRtoLOPval = JanKWPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA have the same median is: %g\" % JanKWPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanKWPRtoBC = sstats.kruskal( np.array( JanPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( JanBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanKWPRtoBCPval = JanKWPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA have the same median is: %g\" % JanKWPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanKWLOtoBC = sstats.kruskal( np.array( JanLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( JanBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanKWLOtoBCPval = JanKWLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA have the same median is: %g\" % JanKWLOtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanLODF[\"Dry_Count\"].median(), JanBCDF[\"Dry_Count\"].median(), JanPRDF[\"Dry_Count\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JanPRQs = JanPRDF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "JanLOQs = JanLODF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "JanBCQs = JanBCDF[\"Dry_Count\"].quantile(q=nCompQs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxQs = max( JanPRQs.max(), JanLOQs.max(), JanBCQs.max() )\n",
    "maxQs = maxQs + 10.0\n",
    "maxQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( JanPRQs, JanLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( JanPRQs, JanBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( JanLOQs, JanBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('Jan Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, maxQs) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( JanPRQs, JanLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( JanPRQs, JanBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( JanLOQs, JanBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('Jan Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 20.0) )\n",
    "ax11.set_ylim( (0.0, 20.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.plot( JanPRQs, nCompQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM\")\n",
    "ax11.plot( JanLOQs, nCompQs, c='xkcd:grass green', marker='o', linestyle='-', label=\"CMIP5 - LOCA\")\n",
    "ax11.plot( JanBCQs, nCompQs, c='xkcd:dark orange', marker='o', linestyle='-', label=\"CMIP5 - BCCA\")\n",
    "ax11.set_title('Jan Empirical CDF', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, 1.1) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.1f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testS = np.array( [ x for x in range(1, int(maxQs) + 1, 1)], dtype=np.int32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRpmf = sstats.nbinom.pmf( testS, PRConvR, PRConvP )\n",
    "LOpmf = sstats.nbinom.pmf( testS, LOConvR, LOConvP )\n",
    "BCpmf = sstats.nbinom.pmf( testS, BCConvR, BCConvP )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.25\n",
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(10.0, 6.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "rects1 = ax11.bar( testS - (0.75*width), PRpmf, width, color=\"xkcd:royal blue\", label=\"PRISM\" )\n",
    "rects2 = ax11.bar( testS, LOpmf, width, color=\"xkcd:grass green\", label=\"LOCA\" )\n",
    "rects3 = ax11.bar( testS + (0.75*width), BCpmf, width, color=\"xkcd:dark orange\", label=\"BCCA\" )\n",
    "ax11.set_title('Jan Fitted Negative Binomial', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 30.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='upper right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.2f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.50\n",
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(10.0, 6.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "rects1 = ax11.bar( testS, PRpmf, width, color=\"xkcd:royal blue\", label=\"PRISM\" )\n",
    "ax11.set_title('Jan Fitted Negative Binomial', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 50.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='upper right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.2f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some theoretical or fit parameters to use later for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebNum = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRConvP = PRDistDF.at[FebNum , HDRS[10]]\n",
    "PRConvR = PRDistDF.at[FebNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOConvP = LODistDF.at[FebNum , HDRS[10]]\n",
    "LOConvR = LODistDF.at[FebNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCConvP = BCDistDF.at[FebNum , HDRS[10]]\n",
    "BCConvR = BCDistDF.at[FebNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian estimates of confidence intervals for mean, variance, and standard deviation of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebPrBSCI = sstats.bayes_mvs( np.array( FebPRDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebPrBSCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebPrBSCI[0][0], FebPrBSCI[0][1][0], FebPrBSCI[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPRMean.append( FebPrBSCI[0][0] )\n",
    "SPRMeanMinCI.append( FebPrBSCI[0][1][0] )\n",
    "SPRMeanMaxCI.append( FebPrBSCI[0][1][1] )\n",
    "SPRVar.append( FebPrBSCI[1][0] )\n",
    "SPRVarMinCI.append( FebPrBSCI[1][1][0] )\n",
    "SPRVarMaxCI.append( FebPrBSCI[1][1][1] )\n",
    "SPRStd.append( FebPrBSCI[2][0] )\n",
    "SPRStdMinCI.append( FebPrBSCI[2][1][0] )\n",
    "SPRStdMaxCI.append( FebPrBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebLOBSCI = sstats.bayes_mvs( np.array( FebLODF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLOMean.append( FebLOBSCI[0][0] )\n",
    "SLOMeanMinCI.append( FebLOBSCI[0][1][0] )\n",
    "SLOMeanMaxCI.append( FebLOBSCI[0][1][1] )\n",
    "SLOVar.append( FebLOBSCI[1][0] )\n",
    "SLOVarMinCI.append( FebLOBSCI[1][1][0] )\n",
    "SLOVarMaxCI.append( FebLOBSCI[1][1][1] )\n",
    "SLOStd.append( FebLOBSCI[2][0] )\n",
    "SLOStdMinCI.append( FebLOBSCI[2][1][0] )\n",
    "SLOStdMaxCI.append( FebLOBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebBCBSCI = sstats.bayes_mvs( np.array( FebBCDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBCMean.append( FebBCBSCI[0][0] )\n",
    "SBCMeanMinCI.append( FebBCBSCI[0][1][0] )\n",
    "SBCMeanMaxCI.append( FebBCBSCI[0][1][1] )\n",
    "SBCVar.append( FebBCBSCI[1][0] )\n",
    "SBCVarMinCI.append( FebBCBSCI[1][1][0] )\n",
    "SBCVarMaxCI.append( FebBCBSCI[1][1][1] )\n",
    "SBCStd.append( FebBCBSCI[2][0] )\n",
    "SBCStdMinCI.append( FebBCBSCI[2][1][0] )\n",
    "SBCStdMaxCI.append( FebBCBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-Test for the means of two independent samples. Two-sided test for the null hypothesis that 2 independent samples hae identical average values. Test assumes that the populations have identical variances.\n",
    "\n",
    "If we observe a large p-value, for example larger than 0.05 or 0.1, then we cannot reject the null hypothesis of identical average scores. If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of equal averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebTTPRtoLO = sstats.ttest_ind( np.array( FebPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( FebLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebTTPRtoLOPval = FebTTPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same population is: %g\" % FebTTPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebTTPRtoBC = sstats.ttest_ind( np.array( FebPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( FebBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebTTPRtoBCPval = FebTTPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same population is: %g\" % FebTTPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebTTLOtoBC = sstats.ttest_ind( np.array( FebLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( FebBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebTTLOtoBCPval = FebTTLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same population is: %g\" % FebTTLOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mann-Whitney Rank Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonparametric test of the null hypothesis that it is equally likely that a randomly selected value from one sample will be less than or greater than a randomly selected value from a second sample. This test can be used to investigate whether two independent samples were selected from populations having the same distribution.\n",
    "\n",
    "Null hypothesis, $H_{0}$, is that the distributions of both populations are equal.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of being from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebMWUPRtoLO = sstats.mannwhitneyu( np.array( FebPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( FebLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebMWUPRtoLOPval = FebMWUPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same distribution is: %g\" % FebMWUPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebMWUPRtoBC = sstats.mannwhitneyu( np.array( FebPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( FebBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebMWUPRtoBCPval = FebMWUPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same distribution is: %g\" % FebMWUPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebMWULOtoBC = sstats.mannwhitneyu( np.array( FebLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( FebBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebMWULOtoBCPval = FebMWULOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same distribution is: %g\" % FebMWULOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kruskal-Wallis Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kruskal-Wallis H-test tests the null hypothesis that the population median of all of the groups are equal. It is a non-parametric version of ANOVA. The test works on 2 or more independent samples, which may have different sizes. Note that rejecting the null hypothesis does not indicate which of the groups differs.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of the same population median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebKWPRtoLO = sstats.kruskal( np.array( FebPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( FebLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebKWPRtoLOPval = FebKWPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA have the same median is: %g\" % FebKWPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebKWPRtoBC = sstats.kruskal( np.array( FebPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( FebBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebKWPRtoBCPval = FebKWPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA have the same median is: %g\" % FebKWPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebKWLOtoBC = sstats.kruskal( np.array( FebLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( FebBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebKWLOtoBCPval = FebKWLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA have the same median is: %g\" % FebKWLOtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebLODF[\"Dry_Count\"].median(), FebBCDF[\"Dry_Count\"].median(), FebPRDF[\"Dry_Count\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FebPRQs = FebPRDF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "FebLOQs = FebLODF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "FebBCQs = FebBCDF[\"Dry_Count\"].quantile(q=nCompQs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxQs = max( FebPRQs.max(), FebLOQs.max(), FebBCQs.max() )\n",
    "maxQs = maxQs + 10.0\n",
    "maxQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( FebPRQs, FebLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( FebPRQs, FebBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( FebLOQs, FebBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('Feb Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, maxQs) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( FebPRQs, FebLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( FebPRQs, FebBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( FebLOQs, FebBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('Feb Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 20.0) )\n",
    "ax11.set_ylim( (0.0, 20.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.plot( FebPRQs, nCompQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM\")\n",
    "ax11.plot( FebLOQs, nCompQs, c='xkcd:grass green', marker='o', linestyle='-', label=\"CMIP5 - LOCA\")\n",
    "ax11.plot( FebBCQs, nCompQs, c='xkcd:dark orange', marker='o', linestyle='-', label=\"CMIP5 - BCCA\")\n",
    "ax11.set_title('Feb Empirical CDF', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, 1.1) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.1f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testS = np.array( [ x for x in range(1, int(maxQs) + 1, 1)], dtype=np.int32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRpmf = sstats.nbinom.pmf( testS, PRConvR, PRConvP )\n",
    "LOpmf = sstats.nbinom.pmf( testS, LOConvR, LOConvP )\n",
    "BCpmf = sstats.nbinom.pmf( testS, BCConvR, BCConvP )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.25\n",
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(10.0, 6.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "rects1 = ax11.bar( testS - (0.75*width), PRpmf, width, color=\"xkcd:royal blue\", label=\"PRISM\" )\n",
    "rects2 = ax11.bar( testS, LOpmf, width, color=\"xkcd:grass green\", label=\"LOCA\" )\n",
    "rects3 = ax11.bar( testS + (0.75*width), BCpmf, width, color=\"xkcd:dark orange\", label=\"BCCA\" )\n",
    "ax11.set_title('Feb Fitted Negative Binomial', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 30.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='upper right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.2f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some theoretical or fit parameters to use later for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarNum = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRConvP = PRDistDF.at[MarNum , HDRS[10]]\n",
    "PRConvR = PRDistDF.at[MarNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOConvP = LODistDF.at[MarNum , HDRS[10]]\n",
    "LOConvR = LODistDF.at[MarNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCConvP = BCDistDF.at[MarNum , HDRS[10]]\n",
    "BCConvR = BCDistDF.at[MarNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian estimates of confidence intervals for mean, variance, and standard deviation of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarPrBSCI = sstats.bayes_mvs( np.array( MarPRDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarPrBSCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarPrBSCI[0][0], MarPrBSCI[0][1][0], MarPrBSCI[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPRMean.append( MarPrBSCI[0][0] )\n",
    "SPRMeanMinCI.append( MarPrBSCI[0][1][0] )\n",
    "SPRMeanMaxCI.append( MarPrBSCI[0][1][1] )\n",
    "SPRVar.append( MarPrBSCI[1][0] )\n",
    "SPRVarMinCI.append( MarPrBSCI[1][1][0] )\n",
    "SPRVarMaxCI.append( MarPrBSCI[1][1][1] )\n",
    "SPRStd.append( MarPrBSCI[2][0] )\n",
    "SPRStdMinCI.append( MarPrBSCI[2][1][0] )\n",
    "SPRStdMaxCI.append( MarPrBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarLOBSCI = sstats.bayes_mvs( np.array( MarLODF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLOMean.append( MarLOBSCI[0][0] )\n",
    "SLOMeanMinCI.append( MarLOBSCI[0][1][0] )\n",
    "SLOMeanMaxCI.append( MarLOBSCI[0][1][1] )\n",
    "SLOVar.append( MarLOBSCI[1][0] )\n",
    "SLOVarMinCI.append( MarLOBSCI[1][1][0] )\n",
    "SLOVarMaxCI.append( MarLOBSCI[1][1][1] )\n",
    "SLOStd.append( MarLOBSCI[2][0] )\n",
    "SLOStdMinCI.append( MarLOBSCI[2][1][0] )\n",
    "SLOStdMaxCI.append( MarLOBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarBCBSCI = sstats.bayes_mvs( np.array( MarBCDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBCMean.append( MarBCBSCI[0][0] )\n",
    "SBCMeanMinCI.append( MarBCBSCI[0][1][0] )\n",
    "SBCMeanMaxCI.append( MarBCBSCI[0][1][1] )\n",
    "SBCVar.append( MarBCBSCI[1][0] )\n",
    "SBCVarMinCI.append( MarBCBSCI[1][1][0] )\n",
    "SBCVarMaxCI.append( MarBCBSCI[1][1][1] )\n",
    "SBCStd.append( MarBCBSCI[2][0] )\n",
    "SBCStdMinCI.append( MarBCBSCI[2][1][0] )\n",
    "SBCStdMaxCI.append( MarBCBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-Test for the means of two independent samples. Two-sided test for the null hypothesis that 2 independent samples hae identical average values. Test assumes that the populations have identical variances.\n",
    "\n",
    "If we observe a large p-value, for example larger than 0.05 or 0.1, then we cannot reject the null hypothesis of identical average scores. If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of equal averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarTTPRtoLO = sstats.ttest_ind( np.array( MarPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( MarLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarTTPRtoLOPval = MarTTPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same population is: %g\" % MarTTPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarTTPRtoBC = sstats.ttest_ind( np.array( MarPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( MarBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarTTPRtoBCPval = MarTTPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same population is: %g\" % MarTTPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarTTLOtoBC = sstats.ttest_ind( np.array( MarLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( MarBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarTTLOtoBCPval = MarTTLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same population is: %g\" % MarTTLOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mann-Whitney Rank Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonparametric test of the null hypothesis that it is equally likely that a randomly selected value from one sample will be less than or greater than a randomly selected value from a second sample. This test can be used to investigate whether two independent samples were selected from populations having the same distribution.\n",
    "\n",
    "Null hypothesis, $H_{0}$, is that the distributions of both populations are equal.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of being from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarMWUPRtoLO = sstats.mannwhitneyu( np.array( MarPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( MarLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarMWUPRtoLOPval = MarMWUPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same distribution is: %g\" % MarMWUPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarMWUPRtoBC = sstats.mannwhitneyu( np.array( MarPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( MarBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarMWUPRtoBCPval = MarMWUPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same distribution is: %g\" % MarMWUPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarMWULOtoBC = sstats.mannwhitneyu( np.array( MarLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( MarBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarMWULOtoBCPval = MarMWULOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same distribution is: %g\" % MarMWULOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kruskal-Wallis Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kruskal-Wallis H-test tests the null hypothesis that the population median of all of the groups are equal. It is a non-parametric version of ANOVA. The test works on 2 or more independent samples, which may have different sizes. Note that rejecting the null hypothesis does not indicate which of the groups differs.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of the same population median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarKWPRtoLO = sstats.kruskal( np.array( MarPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( MarLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarKWPRtoLOPval = MarKWPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA have the same median is: %g\" % MarKWPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarKWPRtoBC = sstats.kruskal( np.array( MarPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( MarBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarKWPRtoBCPval = MarKWPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA have the same median is: %g\" % MarKWPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarKWLOtoBC = sstats.kruskal( np.array( MarLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( MarBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarKWLOtoBCPval = MarKWLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA have the same median is: %g\" % MarKWLOtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarLODF[\"Dry_Count\"].median(), MarBCDF[\"Dry_Count\"].median(), MarPRDF[\"Dry_Count\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarPRQs = MarPRDF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "MarLOQs = MarLODF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "MarBCQs = MarBCDF[\"Dry_Count\"].quantile(q=nCompQs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxQs = max( MarPRQs.max(), MarLOQs.max(), MarBCQs.max() )\n",
    "maxQs = maxQs + 10.0\n",
    "maxQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( MarPRQs, MarLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( MarPRQs, MarBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( MarLOQs, MarBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('Mar Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, maxQs) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( MarPRQs, MarLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( MarPRQs, MarBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( MarLOQs, MarBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('Mar Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 20.0) )\n",
    "ax11.set_ylim( (0.0, 20.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.plot( MarPRQs, nCompQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM\")\n",
    "ax11.plot( MarLOQs, nCompQs, c='xkcd:grass green', marker='o', linestyle='-', label=\"CMIP5 - LOCA\")\n",
    "ax11.plot( MarBCQs, nCompQs, c='xkcd:dark orange', marker='o', linestyle='-', label=\"CMIP5 - BCCA\")\n",
    "ax11.set_title('Mar Empirical CDF', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, 1.1) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.1f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testS = np.array( [ x for x in range(1, int(maxQs) + 1, 1)], dtype=np.int32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRpmf = sstats.nbinom.pmf( testS, PRConvR, PRConvP )\n",
    "LOpmf = sstats.nbinom.pmf( testS, LOConvR, LOConvP )\n",
    "BCpmf = sstats.nbinom.pmf( testS, BCConvR, BCConvP )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.25\n",
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(10.0, 6.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "rects1 = ax11.bar( testS - (0.75*width), PRpmf, width, color=\"xkcd:royal blue\", label=\"PRISM\" )\n",
    "rects2 = ax11.bar( testS, LOpmf, width, color=\"xkcd:grass green\", label=\"LOCA\" )\n",
    "rects3 = ax11.bar( testS + (0.75*width), BCpmf, width, color=\"xkcd:dark orange\", label=\"BCCA\" )\n",
    "ax11.set_title('Mar Fitted Negative Binomial', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 30.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='upper right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.2f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some theoretical or fit parameters to use later for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprNum = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRConvP = PRDistDF.at[AprNum , HDRS[10]]\n",
    "PRConvR = PRDistDF.at[AprNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOConvP = LODistDF.at[AprNum , HDRS[10]]\n",
    "LOConvR = LODistDF.at[AprNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCConvP = BCDistDF.at[AprNum , HDRS[10]]\n",
    "BCConvR = BCDistDF.at[AprNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian estimates of confidence intervals for mean, variance, and standard deviation of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprPrBSCI = sstats.bayes_mvs( np.array( AprPRDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprPrBSCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprPrBSCI[0][0], AprPrBSCI[0][1][0], AprPrBSCI[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPRMean.append( AprPrBSCI[0][0] )\n",
    "SPRMeanMinCI.append( AprPrBSCI[0][1][0] )\n",
    "SPRMeanMaxCI.append( AprPrBSCI[0][1][1] )\n",
    "SPRVar.append( AprPrBSCI[1][0] )\n",
    "SPRVarMinCI.append( AprPrBSCI[1][1][0] )\n",
    "SPRVarMaxCI.append( AprPrBSCI[1][1][1] )\n",
    "SPRStd.append( AprPrBSCI[2][0] )\n",
    "SPRStdMinCI.append( AprPrBSCI[2][1][0] )\n",
    "SPRStdMaxCI.append( AprPrBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprLOBSCI = sstats.bayes_mvs( np.array( AprLODF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLOMean.append( AprLOBSCI[0][0] )\n",
    "SLOMeanMinCI.append( AprLOBSCI[0][1][0] )\n",
    "SLOMeanMaxCI.append( AprLOBSCI[0][1][1] )\n",
    "SLOVar.append( AprLOBSCI[1][0] )\n",
    "SLOVarMinCI.append( AprLOBSCI[1][1][0] )\n",
    "SLOVarMaxCI.append( AprLOBSCI[1][1][1] )\n",
    "SLOStd.append( AprLOBSCI[2][0] )\n",
    "SLOStdMinCI.append( AprLOBSCI[2][1][0] )\n",
    "SLOStdMaxCI.append( AprLOBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprBCBSCI = sstats.bayes_mvs( np.array( AprBCDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBCMean.append( AprBCBSCI[0][0] )\n",
    "SBCMeanMinCI.append( AprBCBSCI[0][1][0] )\n",
    "SBCMeanMaxCI.append( AprBCBSCI[0][1][1] )\n",
    "SBCVar.append( AprBCBSCI[1][0] )\n",
    "SBCVarMinCI.append( AprBCBSCI[1][1][0] )\n",
    "SBCVarMaxCI.append( AprBCBSCI[1][1][1] )\n",
    "SBCStd.append( AprBCBSCI[2][0] )\n",
    "SBCStdMinCI.append( AprBCBSCI[2][1][0] )\n",
    "SBCStdMaxCI.append( AprBCBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-Test for the means of two independent samples. Two-sided test for the null hypothesis that 2 independent samples hae identical average values. Test assumes that the populations have identical variances.\n",
    "\n",
    "If we observe a large p-value, for example larger than 0.05 or 0.1, then we cannot reject the null hypothesis of identical average scores. If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of equal averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprTTPRtoLO = sstats.ttest_ind( np.array( AprPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( AprLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprTTPRtoLOPval = AprTTPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same population is: %g\" % AprTTPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprTTPRtoBC = sstats.ttest_ind( np.array( AprPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( AprBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprTTPRtoBCPval = AprTTPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same population is: %g\" % AprTTPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprTTLOtoBC = sstats.ttest_ind( np.array( AprLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( AprBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprTTLOtoBCPval = AprTTLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same population is: %g\" % AprTTLOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mann-Whitney Rank Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonparametric test of the null hypothesis that it is equally likely that a randomly selected value from one sample will be less than or greater than a randomly selected value from a second sample. This test can be used to investigate whether two independent samples were selected from populations having the same distribution.\n",
    "\n",
    "Null hypothesis, $H_{0}$, is that the distributions of both populations are equal.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of being from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprMWUPRtoLO = sstats.mannwhitneyu( np.array( AprPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( AprLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprMWUPRtoLOPval = AprMWUPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same distribution is: %g\" % AprMWUPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprMWUPRtoBC = sstats.mannwhitneyu( np.array( AprPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( AprBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprMWUPRtoBCPval = AprMWUPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same distribution is: %g\" % AprMWUPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprMWULOtoBC = sstats.mannwhitneyu( np.array( AprLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( AprBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprMWULOtoBCPval = AprMWULOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same distribution is: %g\" % AprMWULOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kruskal-Wallis Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kruskal-Wallis H-test tests the null hypothesis that the population median of all of the groups are equal. It is a non-parametric version of ANOVA. The test works on 2 or more independent samples, which may have different sizes. Note that rejecting the null hypothesis does not indicate which of the groups differs.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of the same population median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprKWPRtoLO = sstats.kruskal( np.array( AprPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( AprLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprKWPRtoLOPval = AprKWPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA have the same median is: %g\" % AprKWPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprKWPRtoBC = sstats.kruskal( np.array( AprPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( AprBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprKWPRtoBCPval = AprKWPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA have the same median is: %g\" % AprKWPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprKWLOtoBC = sstats.kruskal( np.array( AprLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( AprBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprKWLOtoBCPval = AprKWLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA have the same median is: %g\" % AprKWLOtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprLODF[\"Dry_Count\"].median(), AprBCDF[\"Dry_Count\"].median(), AprPRDF[\"Dry_Count\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AprPRQs = AprPRDF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "AprLOQs = AprLODF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "AprBCQs = AprBCDF[\"Dry_Count\"].quantile(q=nCompQs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxQs = max( AprPRQs.max(), AprLOQs.max(), AprBCQs.max() )\n",
    "maxQs = maxQs + 10.0\n",
    "maxQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( AprPRQs, AprLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( AprPRQs, AprBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( AprLOQs, AprBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('Apr Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, maxQs) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( AprPRQs, AprLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( AprPRQs, AprBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( AprLOQs, AprBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('Apr Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 20.0) )\n",
    "ax11.set_ylim( (0.0, 20.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.plot( AprPRQs, nCompQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM\")\n",
    "ax11.plot( AprLOQs, nCompQs, c='xkcd:grass green', marker='o', linestyle='-', label=\"CMIP5 - LOCA\")\n",
    "ax11.plot( AprBCQs, nCompQs, c='xkcd:dark orange', marker='o', linestyle='-', label=\"CMIP5 - BCCA\")\n",
    "ax11.set_title('Apr Empirical CDF', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, 1.1) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.1f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testS = np.array( [ x for x in range(1, int(maxQs) + 1, 1)], dtype=np.int32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRpmf = sstats.nbinom.pmf( testS, PRConvR, PRConvP )\n",
    "LOpmf = sstats.nbinom.pmf( testS, LOConvR, LOConvP )\n",
    "BCpmf = sstats.nbinom.pmf( testS, BCConvR, BCConvP )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.25\n",
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(10.0, 6.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "rects1 = ax11.bar( testS - (0.75*width), PRpmf, width, color=\"xkcd:royal blue\", label=\"PRISM\" )\n",
    "rects2 = ax11.bar( testS, LOpmf, width, color=\"xkcd:grass green\", label=\"LOCA\" )\n",
    "rects3 = ax11.bar( testS + (0.75*width), BCpmf, width, color=\"xkcd:dark orange\", label=\"BCCA\" )\n",
    "ax11.set_title('Apr Fitted Negative Binomial', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 30.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='upper right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.2f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### May"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some theoretical or fit parameters to use later for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayNum = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRConvP = PRDistDF.at[MayNum , HDRS[10]]\n",
    "PRConvR = PRDistDF.at[MayNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOConvP = LODistDF.at[MayNum , HDRS[10]]\n",
    "LOConvR = LODistDF.at[MayNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCConvP = BCDistDF.at[MayNum , HDRS[10]]\n",
    "BCConvR = BCDistDF.at[MayNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian estimates of confidence intervals for mean, variance, and standard deviation of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayPrBSCI = sstats.bayes_mvs( np.array( MayPRDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayPrBSCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayPrBSCI[0][0], MayPrBSCI[0][1][0], MayPrBSCI[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPRMean.append( MayPrBSCI[0][0] )\n",
    "SPRMeanMinCI.append( MayPrBSCI[0][1][0] )\n",
    "SPRMeanMaxCI.append( MayPrBSCI[0][1][1] )\n",
    "SPRVar.append( MayPrBSCI[1][0] )\n",
    "SPRVarMinCI.append( MayPrBSCI[1][1][0] )\n",
    "SPRVarMaxCI.append( MayPrBSCI[1][1][1] )\n",
    "SPRStd.append( MayPrBSCI[2][0] )\n",
    "SPRStdMinCI.append( MayPrBSCI[2][1][0] )\n",
    "SPRStdMaxCI.append( MayPrBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayLOBSCI = sstats.bayes_mvs( np.array( MayLODF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLOMean.append( MayLOBSCI[0][0] )\n",
    "SLOMeanMinCI.append( MayLOBSCI[0][1][0] )\n",
    "SLOMeanMaxCI.append( MayLOBSCI[0][1][1] )\n",
    "SLOVar.append( MayLOBSCI[1][0] )\n",
    "SLOVarMinCI.append( MayLOBSCI[1][1][0] )\n",
    "SLOVarMaxCI.append( MayLOBSCI[1][1][1] )\n",
    "SLOStd.append( MayLOBSCI[2][0] )\n",
    "SLOStdMinCI.append( MayLOBSCI[2][1][0] )\n",
    "SLOStdMaxCI.append( MayLOBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayBCBSCI = sstats.bayes_mvs( np.array( MayBCDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBCMean.append( MayBCBSCI[0][0] )\n",
    "SBCMeanMinCI.append( MayBCBSCI[0][1][0] )\n",
    "SBCMeanMaxCI.append( MayBCBSCI[0][1][1] )\n",
    "SBCVar.append( MayBCBSCI[1][0] )\n",
    "SBCVarMinCI.append( MayBCBSCI[1][1][0] )\n",
    "SBCVarMaxCI.append( MayBCBSCI[1][1][1] )\n",
    "SBCStd.append( MayBCBSCI[2][0] )\n",
    "SBCStdMinCI.append( MayBCBSCI[2][1][0] )\n",
    "SBCStdMaxCI.append( MayBCBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-Test for the means of two independent samples. Two-sided test for the null hypothesis that 2 independent samples hae identical average values. Test assumes that the populations have identical variances.\n",
    "\n",
    "If we observe a large p-value, for example larger than 0.05 or 0.1, then we cannot reject the null hypothesis of identical average scores. If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of equal averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayTTPRtoLO = sstats.ttest_ind( np.array( MayPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( MayLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayTTPRtoLOPval = MayTTPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same population is: %g\" % MayTTPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayTTPRtoBC = sstats.ttest_ind( np.array( MayPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( MayBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayTTPRtoBCPval = MayTTPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same population is: %g\" % MayTTPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayTTLOtoBC = sstats.ttest_ind( np.array( MayLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( MayBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayTTLOtoBCPval = MayTTLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same population is: %g\" % MayTTLOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mann-Whitney Rank Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonparametric test of the null hypothesis that it is equally likely that a randomly selected value from one sample will be less than or greater than a randomly selected value from a second sample. This test can be used to investigate whether two independent samples were selected from populations having the same distribution.\n",
    "\n",
    "Null hypothesis, $H_{0}$, is that the distributions of both populations are equal.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of being from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayMWUPRtoLO = sstats.mannwhitneyu( np.array( MayPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( MayLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayMWUPRtoLOPval = MayMWUPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same distribution is: %g\" % MayMWUPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayMWUPRtoBC = sstats.mannwhitneyu( np.array( MayPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( MayBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayMWUPRtoBCPval = MayMWUPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same distribution is: %g\" % MayMWUPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayMWULOtoBC = sstats.mannwhitneyu( np.array( MayLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( MayBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayMWULOtoBCPval = MayMWULOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same distribution is: %g\" % MayMWULOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kruskal-Wallis Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kruskal-Wallis H-test tests the null hypothesis that the population median of all of the groups are equal. It is a non-parametric version of ANOVA. The test works on 2 or more independent samples, which may have different sizes. Note that rejecting the null hypothesis does not indicate which of the groups differs.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of the same population median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayKWPRtoLO = sstats.kruskal( np.array( MayPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( MayLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayKWPRtoLOPval = MayKWPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA have the same median is: %g\" % MayKWPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayKWPRtoBC = sstats.kruskal( np.array( MayPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( MayBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayKWPRtoBCPval = MayKWPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA have the same median is: %g\" % MayKWPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayKWLOtoBC = sstats.kruskal( np.array( MayLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( MayBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayKWLOtoBCPval = MayKWLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA have the same median is: %g\" % MayKWLOtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayLODF[\"Dry_Count\"].median(), MayBCDF[\"Dry_Count\"].median(), MayPRDF[\"Dry_Count\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MayPRQs = MayPRDF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "MayLOQs = MayLODF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "MayBCQs = MayBCDF[\"Dry_Count\"].quantile(q=nCompQs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxQs = max( MayPRQs.max(), MayLOQs.max(), MayBCQs.max() )\n",
    "maxQs = maxQs + 10.0\n",
    "maxQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( MayPRQs, MayLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( MayPRQs, MayBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( MayLOQs, MayBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('May Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, maxQs) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( MayPRQs, MayLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( MayPRQs, MayBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( MayLOQs, MayBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('May Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 20.0) )\n",
    "ax11.set_ylim( (0.0, 20.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.plot( MayPRQs, nCompQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM\")\n",
    "ax11.plot( MayLOQs, nCompQs, c='xkcd:grass green', marker='o', linestyle='-', label=\"CMIP5 - LOCA\")\n",
    "ax11.plot( MayBCQs, nCompQs, c='xkcd:dark orange', marker='o', linestyle='-', label=\"CMIP5 - BCCA\")\n",
    "ax11.set_title('May Empirical CDF', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, 1.1) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.1f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testS = np.array( [ x for x in range(1, int(maxQs) + 1, 1)], dtype=np.int32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRpmf = sstats.nbinom.pmf( testS, PRConvR, PRConvP )\n",
    "LOpmf = sstats.nbinom.pmf( testS, LOConvR, LOConvP )\n",
    "BCpmf = sstats.nbinom.pmf( testS, BCConvR, BCConvP )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.25\n",
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(10.0, 6.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "rects1 = ax11.bar( testS - (0.75*width), PRpmf, width, color=\"xkcd:royal blue\", label=\"PRISM\" )\n",
    "rects2 = ax11.bar( testS, LOpmf, width, color=\"xkcd:grass green\", label=\"LOCA\" )\n",
    "rects3 = ax11.bar( testS + (0.75*width), BCpmf, width, color=\"xkcd:dark orange\", label=\"BCCA\" )\n",
    "ax11.set_title('May Fitted Negative Binomial', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 30.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='upper right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.2f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some theoretical or fit parameters to use later for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunNum = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRConvP = PRDistDF.at[JunNum , HDRS[10]]\n",
    "PRConvR = PRDistDF.at[JunNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOConvP = LODistDF.at[JunNum , HDRS[10]]\n",
    "LOConvR = LODistDF.at[JunNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCConvP = BCDistDF.at[JunNum , HDRS[10]]\n",
    "BCConvR = BCDistDF.at[JunNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian estimates of confidence intervals for mean, variance, and standard deviation of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunPrBSCI = sstats.bayes_mvs( np.array( JunPRDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunPrBSCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunPrBSCI[0][0], JunPrBSCI[0][1][0], JunPrBSCI[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPRMean.append( JunPrBSCI[0][0] )\n",
    "SPRMeanMinCI.append( JunPrBSCI[0][1][0] )\n",
    "SPRMeanMaxCI.append( JunPrBSCI[0][1][1] )\n",
    "SPRVar.append( JunPrBSCI[1][0] )\n",
    "SPRVarMinCI.append( JunPrBSCI[1][1][0] )\n",
    "SPRVarMaxCI.append( JunPrBSCI[1][1][1] )\n",
    "SPRStd.append( JunPrBSCI[2][0] )\n",
    "SPRStdMinCI.append( JunPrBSCI[2][1][0] )\n",
    "SPRStdMaxCI.append( JunPrBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunLOBSCI = sstats.bayes_mvs( np.array( JunLODF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLOMean.append( JunLOBSCI[0][0] )\n",
    "SLOMeanMinCI.append( JunLOBSCI[0][1][0] )\n",
    "SLOMeanMaxCI.append( JunLOBSCI[0][1][1] )\n",
    "SLOVar.append( JunLOBSCI[1][0] )\n",
    "SLOVarMinCI.append( JunLOBSCI[1][1][0] )\n",
    "SLOVarMaxCI.append( JunLOBSCI[1][1][1] )\n",
    "SLOStd.append( JunLOBSCI[2][0] )\n",
    "SLOStdMinCI.append( JunLOBSCI[2][1][0] )\n",
    "SLOStdMaxCI.append( JunLOBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunBCBSCI = sstats.bayes_mvs( np.array( JunBCDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBCMean.append( JunBCBSCI[0][0] )\n",
    "SBCMeanMinCI.append( JunBCBSCI[0][1][0] )\n",
    "SBCMeanMaxCI.append( JunBCBSCI[0][1][1] )\n",
    "SBCVar.append( JunBCBSCI[1][0] )\n",
    "SBCVarMinCI.append( JunBCBSCI[1][1][0] )\n",
    "SBCVarMaxCI.append( JunBCBSCI[1][1][1] )\n",
    "SBCStd.append( JunBCBSCI[2][0] )\n",
    "SBCStdMinCI.append( JunBCBSCI[2][1][0] )\n",
    "SBCStdMaxCI.append( JunBCBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-Test for the means of two independent samples. Two-sided test for the null hypothesis that 2 independent samples hae identical average values. Test assumes that the populations have identical variances.\n",
    "\n",
    "If we observe a large p-value, for example larger than 0.05 or 0.1, then we cannot reject the null hypothesis of identical average scores. If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of equal averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunTTPRtoLO = sstats.ttest_ind( np.array( JunPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( JunLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunTTPRtoLOPval = JunTTPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same population is: %g\" % JunTTPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunTTPRtoBC = sstats.ttest_ind( np.array( JunPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( JunBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunTTPRtoBCPval = JunTTPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same population is: %g\" % JunTTPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunTTLOtoBC = sstats.ttest_ind( np.array( JunLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( JunBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunTTLOtoBCPval = JunTTLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same population is: %g\" % JunTTLOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mann-Whitney Rank Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonparametric test of the null hypothesis that it is equally likely that a randomly selected value from one sample will be less than or greater than a randomly selected value from a second sample. This test can be used to investigate whether two independent samples were selected from populations having the same distribution.\n",
    "\n",
    "Null hypothesis, $H_{0}$, is that the distributions of both populations are equal.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of being from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunMWUPRtoLO = sstats.mannwhitneyu( np.array( JunPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( JunLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunMWUPRtoLOPval = JunMWUPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same distribution is: %g\" % JunMWUPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunMWUPRtoBC = sstats.mannwhitneyu( np.array( JunPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( JunBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunMWUPRtoBCPval = JunMWUPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same distribution is: %g\" % JunMWUPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunMWULOtoBC = sstats.mannwhitneyu( np.array( JunLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( JunBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunMWULOtoBCPval = JunMWULOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same distribution is: %g\" % JunMWULOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kruskal-Wallis Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kruskal-Wallis H-test tests the null hypothesis that the population median of all of the groups are equal. It is a non-parametric version of ANOVA. The test works on 2 or more independent samples, which may have different sizes. Note that rejecting the null hypothesis does not indicate which of the groups differs.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of the same population median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunKWPRtoLO = sstats.kruskal( np.array( JunPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( JunLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunKWPRtoLOPval = JunKWPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA have the same median is: %g\" % JunKWPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunKWPRtoBC = sstats.kruskal( np.array( JunPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( JunBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunKWPRtoBCPval = JunKWPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA have the same median is: %g\" % JunKWPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunKWLOtoBC = sstats.kruskal( np.array( JunLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( JunBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunKWLOtoBCPval = JunKWLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA have the same median is: %g\" % JunKWLOtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunLODF[\"Dry_Count\"].median(), JunBCDF[\"Dry_Count\"].median(), JunPRDF[\"Dry_Count\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JunPRQs = JunPRDF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "JunLOQs = JunLODF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "JunBCQs = JunBCDF[\"Dry_Count\"].quantile(q=nCompQs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxQs = max( JunPRQs.max(), JunLOQs.max(), JunBCQs.max() )\n",
    "maxQs = maxQs + 10.0\n",
    "maxQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( JunPRQs, JunLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( JunPRQs, JunBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( JunLOQs, JunBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('Jun Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, maxQs) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( JunPRQs, JunLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( JunPRQs, JunBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( JunLOQs, JunBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('Jun Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 20.0) )\n",
    "ax11.set_ylim( (0.0, 20.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.plot( JunPRQs, nCompQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM\")\n",
    "ax11.plot( JunLOQs, nCompQs, c='xkcd:grass green', marker='o', linestyle='-', label=\"CMIP5 - LOCA\")\n",
    "ax11.plot( JunBCQs, nCompQs, c='xkcd:dark orange', marker='o', linestyle='-', label=\"CMIP5 - BCCA\")\n",
    "ax11.set_title('Jun Empirical CDF', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, 1.1) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.1f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testS = np.array( [ x for x in range(1, int(maxQs) + 1, 1)], dtype=np.int32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRpmf = sstats.nbinom.pmf( testS, PRConvR, PRConvP )\n",
    "LOpmf = sstats.nbinom.pmf( testS, LOConvR, LOConvP )\n",
    "BCpmf = sstats.nbinom.pmf( testS, BCConvR, BCConvP )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.25\n",
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(10.0, 6.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "rects1 = ax11.bar( testS - (0.75*width), PRpmf, width, color=\"xkcd:royal blue\", label=\"PRISM\" )\n",
    "rects2 = ax11.bar( testS, LOpmf, width, color=\"xkcd:grass green\", label=\"LOCA\" )\n",
    "rects3 = ax11.bar( testS + (0.75*width), BCpmf, width, color=\"xkcd:dark orange\", label=\"BCCA\" )\n",
    "ax11.set_title('Jun Fitted Negative Binomial', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 30.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='upper right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.2f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some theoretical or fit parameters to use later for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulNum = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRConvP = PRDistDF.at[JulNum , HDRS[10]]\n",
    "PRConvR = PRDistDF.at[JulNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOConvP = LODistDF.at[JulNum , HDRS[10]]\n",
    "LOConvR = LODistDF.at[JulNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCConvP = BCDistDF.at[JulNum , HDRS[10]]\n",
    "BCConvR = BCDistDF.at[JulNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian estimates of confidence intervals for mean, variance, and standard deviation of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulPrBSCI = sstats.bayes_mvs( np.array( JulPRDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulPrBSCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulPrBSCI[0][0], JulPrBSCI[0][1][0], JulPrBSCI[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPRMean.append( JulPrBSCI[0][0] )\n",
    "SPRMeanMinCI.append( JulPrBSCI[0][1][0] )\n",
    "SPRMeanMaxCI.append( JulPrBSCI[0][1][1] )\n",
    "SPRVar.append( JulPrBSCI[1][0] )\n",
    "SPRVarMinCI.append( JulPrBSCI[1][1][0] )\n",
    "SPRVarMaxCI.append( JulPrBSCI[1][1][1] )\n",
    "SPRStd.append( JulPrBSCI[2][0] )\n",
    "SPRStdMinCI.append( JulPrBSCI[2][1][0] )\n",
    "SPRStdMaxCI.append( JulPrBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulLOBSCI = sstats.bayes_mvs( np.array( JulLODF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLOMean.append( JulLOBSCI[0][0] )\n",
    "SLOMeanMinCI.append( JulLOBSCI[0][1][0] )\n",
    "SLOMeanMaxCI.append( JulLOBSCI[0][1][1] )\n",
    "SLOVar.append( JulLOBSCI[1][0] )\n",
    "SLOVarMinCI.append( JulLOBSCI[1][1][0] )\n",
    "SLOVarMaxCI.append( JulLOBSCI[1][1][1] )\n",
    "SLOStd.append( JulLOBSCI[2][0] )\n",
    "SLOStdMinCI.append( JulLOBSCI[2][1][0] )\n",
    "SLOStdMaxCI.append( JulLOBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulBCBSCI = sstats.bayes_mvs( np.array( JulBCDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBCMean.append( JulBCBSCI[0][0] )\n",
    "SBCMeanMinCI.append( JulBCBSCI[0][1][0] )\n",
    "SBCMeanMaxCI.append( JulBCBSCI[0][1][1] )\n",
    "SBCVar.append( JulBCBSCI[1][0] )\n",
    "SBCVarMinCI.append( JulBCBSCI[1][1][0] )\n",
    "SBCVarMaxCI.append( JulBCBSCI[1][1][1] )\n",
    "SBCStd.append( JulBCBSCI[2][0] )\n",
    "SBCStdMinCI.append( JulBCBSCI[2][1][0] )\n",
    "SBCStdMaxCI.append( JulBCBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-Test for the means of two independent samples. Two-sided test for the null hypothesis that 2 independent samples hae identical average values. Test assumes that the populations have identical variances.\n",
    "\n",
    "If we observe a large p-value, for example larger than 0.05 or 0.1, then we cannot reject the null hypothesis of identical average scores. If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of equal averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulTTPRtoLO = sstats.ttest_ind( np.array( JulPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( JulLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulTTPRtoLOPval = JulTTPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same population is: %g\" % JulTTPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulTTPRtoBC = sstats.ttest_ind( np.array( JulPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( JulBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulTTPRtoBCPval = JulTTPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same population is: %g\" % JulTTPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulTTLOtoBC = sstats.ttest_ind( np.array( JulLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( JulBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulTTLOtoBCPval = JulTTLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same population is: %g\" % JulTTLOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mann-Whitney Rank Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonparametric test of the null hypothesis that it is equally likely that a randomly selected value from one sample will be less than or greater than a randomly selected value from a second sample. This test can be used to investigate whether two independent samples were selected from populations having the same distribution.\n",
    "\n",
    "Null hypothesis, $H_{0}$, is that the distributions of both populations are equal.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of being from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulMWUPRtoLO = sstats.mannwhitneyu( np.array( JulPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( JulLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulMWUPRtoLOPval = JulMWUPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same distribution is: %g\" % JulMWUPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulMWUPRtoBC = sstats.mannwhitneyu( np.array( JulPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( JulBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulMWUPRtoBCPval = JulMWUPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same distribution is: %g\" % JulMWUPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulMWULOtoBC = sstats.mannwhitneyu( np.array( JulLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( JulBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulMWULOtoBCPval = JulMWULOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same distribution is: %g\" % JulMWULOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kruskal-Wallis Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kruskal-Wallis H-test tests the null hypothesis that the population median of all of the groups are equal. It is a non-parametric version of ANOVA. The test works on 2 or more independent samples, which may have different sizes. Note that rejecting the null hypothesis does not indicate which of the groups differs.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of the same population median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulKWPRtoLO = sstats.kruskal( np.array( JulPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( JulLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulKWPRtoLOPval = JulKWPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA have the same median is: %g\" % JulKWPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulKWPRtoBC = sstats.kruskal( np.array( JulPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( JulBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulKWPRtoBCPval = JulKWPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA have the same median is: %g\" % JulKWPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulKWLOtoBC = sstats.kruskal( np.array( JulLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( JulBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulKWLOtoBCPval = JulKWLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA have the same median is: %g\" % JulKWLOtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulLODF[\"Dry_Count\"].median(), JulBCDF[\"Dry_Count\"].median(), JulPRDF[\"Dry_Count\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JulPRQs = JulPRDF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "JulLOQs = JulLODF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "JulBCQs = JulBCDF[\"Dry_Count\"].quantile(q=nCompQs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxQs = max( JulPRQs.max(), JulLOQs.max(), JulBCQs.max() )\n",
    "maxQs = maxQs + 10.0\n",
    "maxQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( JulPRQs, JulLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( JulPRQs, JulBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( JulLOQs, JulBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('Jul Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, maxQs) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( JulPRQs, JulLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( JulPRQs, JulBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( JulLOQs, JulBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('Jul Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 20.0) )\n",
    "ax11.set_ylim( (0.0, 20.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.plot( JulPRQs, nCompQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM\")\n",
    "ax11.plot( JulLOQs, nCompQs, c='xkcd:grass green', marker='o', linestyle='-', label=\"CMIP5 - LOCA\")\n",
    "ax11.plot( JulBCQs, nCompQs, c='xkcd:dark orange', marker='o', linestyle='-', label=\"CMIP5 - BCCA\")\n",
    "ax11.set_title('Jul Empirical CDF', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, 1.1) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.1f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testS = np.array( [ x for x in range(1, int(maxQs) + 1, 1)], dtype=np.int32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRpmf = sstats.nbinom.pmf( testS, PRConvR, PRConvP )\n",
    "LOpmf = sstats.nbinom.pmf( testS, LOConvR, LOConvP )\n",
    "BCpmf = sstats.nbinom.pmf( testS, BCConvR, BCConvP )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.25\n",
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(10.0, 6.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "rects1 = ax11.bar( testS - (0.75*width), PRpmf, width, color=\"xkcd:royal blue\", label=\"PRISM\" )\n",
    "rects2 = ax11.bar( testS, LOpmf, width, color=\"xkcd:grass green\", label=\"LOCA\" )\n",
    "rects3 = ax11.bar( testS + (0.75*width), BCpmf, width, color=\"xkcd:dark orange\", label=\"BCCA\" )\n",
    "ax11.set_title('Jul Fitted Negative Binomial', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 30.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='upper right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.2f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some theoretical or fit parameters to use later for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugNum = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRConvP = PRDistDF.at[AugNum , HDRS[10]]\n",
    "PRConvR = PRDistDF.at[AugNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOConvP = LODistDF.at[AugNum , HDRS[10]]\n",
    "LOConvR = LODistDF.at[AugNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCConvP = BCDistDF.at[AugNum , HDRS[10]]\n",
    "BCConvR = BCDistDF.at[AugNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian estimates of confidence intervals for mean, variance, and standard deviation of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugPrBSCI = sstats.bayes_mvs( np.array( AugPRDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugPrBSCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugPrBSCI[0][0], AugPrBSCI[0][1][0], AugPrBSCI[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPRMean.append( AugPrBSCI[0][0] )\n",
    "SPRMeanMinCI.append( AugPrBSCI[0][1][0] )\n",
    "SPRMeanMaxCI.append( AugPrBSCI[0][1][1] )\n",
    "SPRVar.append( AugPrBSCI[1][0] )\n",
    "SPRVarMinCI.append( AugPrBSCI[1][1][0] )\n",
    "SPRVarMaxCI.append( AugPrBSCI[1][1][1] )\n",
    "SPRStd.append( AugPrBSCI[2][0] )\n",
    "SPRStdMinCI.append( AugPrBSCI[2][1][0] )\n",
    "SPRStdMaxCI.append( AugPrBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugLOBSCI = sstats.bayes_mvs( np.array( AugLODF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLOMean.append( AugLOBSCI[0][0] )\n",
    "SLOMeanMinCI.append( AugLOBSCI[0][1][0] )\n",
    "SLOMeanMaxCI.append( AugLOBSCI[0][1][1] )\n",
    "SLOVar.append( AugLOBSCI[1][0] )\n",
    "SLOVarMinCI.append( AugLOBSCI[1][1][0] )\n",
    "SLOVarMaxCI.append( AugLOBSCI[1][1][1] )\n",
    "SLOStd.append( AugLOBSCI[2][0] )\n",
    "SLOStdMinCI.append( AugLOBSCI[2][1][0] )\n",
    "SLOStdMaxCI.append( AugLOBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugBCBSCI = sstats.bayes_mvs( np.array( AugBCDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBCMean.append( AugBCBSCI[0][0] )\n",
    "SBCMeanMinCI.append( AugBCBSCI[0][1][0] )\n",
    "SBCMeanMaxCI.append( AugBCBSCI[0][1][1] )\n",
    "SBCVar.append( AugBCBSCI[1][0] )\n",
    "SBCVarMinCI.append( AugBCBSCI[1][1][0] )\n",
    "SBCVarMaxCI.append( AugBCBSCI[1][1][1] )\n",
    "SBCStd.append( AugBCBSCI[2][0] )\n",
    "SBCStdMinCI.append( AugBCBSCI[2][1][0] )\n",
    "SBCStdMaxCI.append( AugBCBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-Test for the means of two independent samples. Two-sided test for the null hypothesis that 2 independent samples hae identical average values. Test assumes that the populations have identical variances.\n",
    "\n",
    "If we observe a large p-value, for example larger than 0.05 or 0.1, then we cannot reject the null hypothesis of identical average scores. If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of equal averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugTTPRtoLO = sstats.ttest_ind( np.array( AugPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( AugLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugTTPRtoLOPval = AugTTPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same population is: %g\" % AugTTPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugTTPRtoBC = sstats.ttest_ind( np.array( AugPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( AugBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugTTPRtoBCPval = AugTTPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same population is: %g\" % AugTTPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugTTLOtoBC = sstats.ttest_ind( np.array( AugLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( AugBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugTTLOtoBCPval = AugTTLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same population is: %g\" % AugTTLOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mann-Whitney Rank Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonparametric test of the null hypothesis that it is equally likely that a randomly selected value from one sample will be less than or greater than a randomly selected value from a second sample. This test can be used to investigate whether two independent samples were selected from populations having the same distribution.\n",
    "\n",
    "Null hypothesis, $H_{0}$, is that the distributions of both populations are equal.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of being from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugMWUPRtoLO = sstats.mannwhitneyu( np.array( AugPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( AugLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugMWUPRtoLOPval = AugMWUPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same distribution is: %g\" % AugMWUPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugMWUPRtoBC = sstats.mannwhitneyu( np.array( AugPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( AugBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugMWUPRtoBCPval = AugMWUPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same distribution is: %g\" % AugMWUPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugMWULOtoBC = sstats.mannwhitneyu( np.array( AugLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( AugBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugMWULOtoBCPval = AugMWULOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same distribution is: %g\" % AugMWULOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kruskal-Wallis Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kruskal-Wallis H-test tests the null hypothesis that the population median of all of the groups are equal. It is a non-parametric version of ANOVA. The test works on 2 or more independent samples, which may have different sizes. Note that rejecting the null hypothesis does not indicate which of the groups differs.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of the same population median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugKWPRtoLO = sstats.kruskal( np.array( AugPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( AugLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugKWPRtoLOPval = AugKWPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA have the same median is: %g\" % AugKWPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugKWPRtoBC = sstats.kruskal( np.array( AugPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( AugBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugKWPRtoBCPval = AugKWPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA have the same median is: %g\" % AugKWPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugKWLOtoBC = sstats.kruskal( np.array( AugLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( AugBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugKWLOtoBCPval = AugKWLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA have the same median is: %g\" % AugKWLOtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugLODF[\"Dry_Count\"].median(), AugBCDF[\"Dry_Count\"].median(), AugPRDF[\"Dry_Count\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AugPRQs = AugPRDF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "AugLOQs = AugLODF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "AugBCQs = AugBCDF[\"Dry_Count\"].quantile(q=nCompQs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxQs = max( AugPRQs.max(), AugLOQs.max(), AugBCQs.max() )\n",
    "maxQs = maxQs + 10.0\n",
    "maxQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( AugPRQs, AugLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( AugPRQs, AugBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( AugLOQs, AugBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('Aug Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, maxQs) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( AugPRQs, AugLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( AugPRQs, AugBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( AugLOQs, AugBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('Aug Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 20.0) )\n",
    "ax11.set_ylim( (0.0, 20.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.plot( AugPRQs, nCompQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM\")\n",
    "ax11.plot( AugLOQs, nCompQs, c='xkcd:grass green', marker='o', linestyle='-', label=\"CMIP5 - LOCA\")\n",
    "ax11.plot( AugBCQs, nCompQs, c='xkcd:dark orange', marker='o', linestyle='-', label=\"CMIP5 - BCCA\")\n",
    "ax11.set_title('Aug Empirical CDF', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, 1.1) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.1f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testS = np.array( [ x for x in range(1, int(maxQs) + 1, 1)], dtype=np.int32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRpmf = sstats.nbinom.pmf( testS, PRConvR, PRConvP )\n",
    "LOpmf = sstats.nbinom.pmf( testS, LOConvR, LOConvP )\n",
    "BCpmf = sstats.nbinom.pmf( testS, BCConvR, BCConvP )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.25\n",
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(10.0, 6.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "rects1 = ax11.bar( testS - (0.75*width), PRpmf, width, color=\"xkcd:royal blue\", label=\"PRISM\" )\n",
    "rects2 = ax11.bar( testS, LOpmf, width, color=\"xkcd:grass green\", label=\"LOCA\" )\n",
    "rects3 = ax11.bar( testS + (0.75*width), BCpmf, width, color=\"xkcd:dark orange\", label=\"BCCA\" )\n",
    "ax11.set_title('Aug Fitted Negative Binomial', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 30.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='upper right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.2f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some theoretical or fit parameters to use later for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepNum = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRConvP = PRDistDF.at[SepNum , HDRS[10]]\n",
    "PRConvR = PRDistDF.at[SepNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOConvP = LODistDF.at[SepNum , HDRS[10]]\n",
    "LOConvR = LODistDF.at[SepNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCConvP = BCDistDF.at[SepNum , HDRS[10]]\n",
    "BCConvR = BCDistDF.at[SepNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian estimates of confidence intervals for mean, variance, and standard deviation of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepPrBSCI = sstats.bayes_mvs( np.array( SepPRDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepPrBSCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepPrBSCI[0][0], SepPrBSCI[0][1][0], SepPrBSCI[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPRMean.append( SepPrBSCI[0][0] )\n",
    "SPRMeanMinCI.append( SepPrBSCI[0][1][0] )\n",
    "SPRMeanMaxCI.append( SepPrBSCI[0][1][1] )\n",
    "SPRVar.append( SepPrBSCI[1][0] )\n",
    "SPRVarMinCI.append( SepPrBSCI[1][1][0] )\n",
    "SPRVarMaxCI.append( SepPrBSCI[1][1][1] )\n",
    "SPRStd.append( SepPrBSCI[2][0] )\n",
    "SPRStdMinCI.append( SepPrBSCI[2][1][0] )\n",
    "SPRStdMaxCI.append( SepPrBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepLOBSCI = sstats.bayes_mvs( np.array( SepLODF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLOMean.append( SepLOBSCI[0][0] )\n",
    "SLOMeanMinCI.append( SepLOBSCI[0][1][0] )\n",
    "SLOMeanMaxCI.append( SepLOBSCI[0][1][1] )\n",
    "SLOVar.append( SepLOBSCI[1][0] )\n",
    "SLOVarMinCI.append( SepLOBSCI[1][1][0] )\n",
    "SLOVarMaxCI.append( SepLOBSCI[1][1][1] )\n",
    "SLOStd.append( SepLOBSCI[2][0] )\n",
    "SLOStdMinCI.append( SepLOBSCI[2][1][0] )\n",
    "SLOStdMaxCI.append( SepLOBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepBCBSCI = sstats.bayes_mvs( np.array( SepBCDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBCMean.append( SepBCBSCI[0][0] )\n",
    "SBCMeanMinCI.append( SepBCBSCI[0][1][0] )\n",
    "SBCMeanMaxCI.append( SepBCBSCI[0][1][1] )\n",
    "SBCVar.append( SepBCBSCI[1][0] )\n",
    "SBCVarMinCI.append( SepBCBSCI[1][1][0] )\n",
    "SBCVarMaxCI.append( SepBCBSCI[1][1][1] )\n",
    "SBCStd.append( SepBCBSCI[2][0] )\n",
    "SBCStdMinCI.append( SepBCBSCI[2][1][0] )\n",
    "SBCStdMaxCI.append( SepBCBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-Test for the means of two independent samples. Two-sided test for the null hypothesis that 2 independent samples hae identical average values. Test assumes that the populations have identical variances.\n",
    "\n",
    "If we observe a large p-value, for example larger than 0.05 or 0.1, then we cannot reject the null hypothesis of identical average scores. If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of equal averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepTTPRtoLO = sstats.ttest_ind( np.array( SepPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( SepLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepTTPRtoLOPval = SepTTPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same population is: %g\" % SepTTPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepTTPRtoBC = sstats.ttest_ind( np.array( SepPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( SepBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepTTPRtoBCPval = SepTTPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same population is: %g\" % SepTTPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepTTLOtoBC = sstats.ttest_ind( np.array( SepLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( SepBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepTTLOtoBCPval = SepTTLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same population is: %g\" % SepTTLOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mann-Whitney Rank Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonparametric test of the null hypothesis that it is equally likely that a randomly selected value from one sample will be less than or greater than a randomly selected value from a second sample. This test can be used to investigate whether two independent samples were selected from populations having the same distribution.\n",
    "\n",
    "Null hypothesis, $H_{0}$, is that the distributions of both populations are equal.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of being from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepMWUPRtoLO = sstats.mannwhitneyu( np.array( SepPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( SepLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepMWUPRtoLOPval = SepMWUPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same distribution is: %g\" % SepMWUPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepMWUPRtoBC = sstats.mannwhitneyu( np.array( SepPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( SepBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepMWUPRtoBCPval = SepMWUPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same distribution is: %g\" % SepMWUPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepMWULOtoBC = sstats.mannwhitneyu( np.array( SepLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( SepBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepMWULOtoBCPval = SepMWULOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same distribution is: %g\" % SepMWULOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kruskal-Wallis Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kruskal-Wallis H-test tests the null hypothesis that the population median of all of the groups are equal. It is a non-parametric version of ANOVA. The test works on 2 or more independent samples, which may have different sizes. Note that rejecting the null hypothesis does not indicate which of the groups differs.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of the same population median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepKWPRtoLO = sstats.kruskal( np.array( SepPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( SepLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepKWPRtoLOPval = SepKWPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA have the same median is: %g\" % SepKWPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepKWPRtoBC = sstats.kruskal( np.array( SepPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( SepBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepKWPRtoBCPval = SepKWPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA have the same median is: %g\" % SepKWPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepKWLOtoBC = sstats.kruskal( np.array( SepLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( SepBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepKWLOtoBCPval = SepKWLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA have the same median is: %g\" % SepKWLOtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepLODF[\"Dry_Count\"].median(), SepBCDF[\"Dry_Count\"].median(), SepPRDF[\"Dry_Count\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SepPRQs = SepPRDF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "SepLOQs = SepLODF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "SepBCQs = SepBCDF[\"Dry_Count\"].quantile(q=nCompQs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxQs = max( SepPRQs.max(), SepLOQs.max(), SepBCQs.max() )\n",
    "maxQs = maxQs + 10.0\n",
    "maxQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( SepPRQs, SepLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( SepPRQs, SepBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( SepLOQs, SepBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('Sep Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, maxQs) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( SepPRQs, SepLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( SepPRQs, SepBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( SepLOQs, SepBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('Sep Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 20.0) )\n",
    "ax11.set_ylim( (0.0, 20.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.plot( SepPRQs, nCompQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM\")\n",
    "ax11.plot( SepLOQs, nCompQs, c='xkcd:grass green', marker='o', linestyle='-', label=\"CMIP5 - LOCA\")\n",
    "ax11.plot( SepBCQs, nCompQs, c='xkcd:dark orange', marker='o', linestyle='-', label=\"CMIP5 - BCCA\")\n",
    "ax11.set_title('Sep Empirical CDF', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, 1.1) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.1f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testS = np.array( [ x for x in range(1, int(maxQs) + 1, 1)], dtype=np.int32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRpmf = sstats.nbinom.pmf( testS, PRConvR, PRConvP )\n",
    "LOpmf = sstats.nbinom.pmf( testS, LOConvR, LOConvP )\n",
    "BCpmf = sstats.nbinom.pmf( testS, BCConvR, BCConvP )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.25\n",
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(10.0, 6.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "rects1 = ax11.bar( testS - (0.75*width), PRpmf, width, color=\"xkcd:royal blue\", label=\"PRISM\" )\n",
    "rects2 = ax11.bar( testS, LOpmf, width, color=\"xkcd:grass green\", label=\"LOCA\" )\n",
    "rects3 = ax11.bar( testS + (0.75*width), BCpmf, width, color=\"xkcd:dark orange\", label=\"BCCA\" )\n",
    "ax11.set_title('Sep Fitted Negative Binomial', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 30.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='upper right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.2f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some theoretical or fit parameters to use later for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctNum = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRConvP = PRDistDF.at[OctNum , HDRS[10]]\n",
    "PRConvR = PRDistDF.at[OctNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOConvP = LODistDF.at[OctNum , HDRS[10]]\n",
    "LOConvR = LODistDF.at[OctNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCConvP = BCDistDF.at[OctNum , HDRS[10]]\n",
    "BCConvR = BCDistDF.at[OctNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian estimates of confidence intervals for mean, variance, and standard deviation of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctPrBSCI = sstats.bayes_mvs( np.array( OctPRDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctPrBSCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctPrBSCI[0][0], OctPrBSCI[0][1][0], OctPrBSCI[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPRMean.append( OctPrBSCI[0][0] )\n",
    "SPRMeanMinCI.append( OctPrBSCI[0][1][0] )\n",
    "SPRMeanMaxCI.append( OctPrBSCI[0][1][1] )\n",
    "SPRVar.append( OctPrBSCI[1][0] )\n",
    "SPRVarMinCI.append( OctPrBSCI[1][1][0] )\n",
    "SPRVarMaxCI.append( OctPrBSCI[1][1][1] )\n",
    "SPRStd.append( OctPrBSCI[2][0] )\n",
    "SPRStdMinCI.append( OctPrBSCI[2][1][0] )\n",
    "SPRStdMaxCI.append( OctPrBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctLOBSCI = sstats.bayes_mvs( np.array( OctLODF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLOMean.append( OctLOBSCI[0][0] )\n",
    "SLOMeanMinCI.append( OctLOBSCI[0][1][0] )\n",
    "SLOMeanMaxCI.append( OctLOBSCI[0][1][1] )\n",
    "SLOVar.append( OctLOBSCI[1][0] )\n",
    "SLOVarMinCI.append( OctLOBSCI[1][1][0] )\n",
    "SLOVarMaxCI.append( OctLOBSCI[1][1][1] )\n",
    "SLOStd.append( OctLOBSCI[2][0] )\n",
    "SLOStdMinCI.append( OctLOBSCI[2][1][0] )\n",
    "SLOStdMaxCI.append( OctLOBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctBCBSCI = sstats.bayes_mvs( np.array( OctBCDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBCMean.append( OctBCBSCI[0][0] )\n",
    "SBCMeanMinCI.append( OctBCBSCI[0][1][0] )\n",
    "SBCMeanMaxCI.append( OctBCBSCI[0][1][1] )\n",
    "SBCVar.append( OctBCBSCI[1][0] )\n",
    "SBCVarMinCI.append( OctBCBSCI[1][1][0] )\n",
    "SBCVarMaxCI.append( OctBCBSCI[1][1][1] )\n",
    "SBCStd.append( OctBCBSCI[2][0] )\n",
    "SBCStdMinCI.append( OctBCBSCI[2][1][0] )\n",
    "SBCStdMaxCI.append( OctBCBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-Test for the means of two independent samples. Two-sided test for the null hypothesis that 2 independent samples hae identical average values. Test assumes that the populations have identical variances.\n",
    "\n",
    "If we observe a large p-value, for example larger than 0.05 or 0.1, then we cannot reject the null hypothesis of identical average scores. If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of equal averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctTTPRtoLO = sstats.ttest_ind( np.array( OctPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( OctLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctTTPRtoLOPval = OctTTPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same population is: %g\" % OctTTPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctTTPRtoBC = sstats.ttest_ind( np.array( OctPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( OctBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctTTPRtoBCPval = OctTTPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same population is: %g\" % OctTTPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctTTLOtoBC = sstats.ttest_ind( np.array( OctLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( OctBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctTTLOtoBCPval = OctTTLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same population is: %g\" % OctTTLOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mann-Whitney Rank Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonparametric test of the null hypothesis that it is equally likely that a randomly selected value from one sample will be less than or greater than a randomly selected value from a second sample. This test can be used to investigate whether two independent samples were selected from populations having the same distribution.\n",
    "\n",
    "Null hypothesis, $H_{0}$, is that the distributions of both populations are equal.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of being from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctMWUPRtoLO = sstats.mannwhitneyu( np.array( OctPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( OctLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctMWUPRtoLOPval = OctMWUPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same distribution is: %g\" % OctMWUPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctMWUPRtoBC = sstats.mannwhitneyu( np.array( OctPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( OctBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctMWUPRtoBCPval = OctMWUPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same distribution is: %g\" % OctMWUPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctMWULOtoBC = sstats.mannwhitneyu( np.array( OctLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( OctBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctMWULOtoBCPval = OctMWULOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same distribution is: %g\" % OctMWULOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kruskal-Wallis Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kruskal-Wallis H-test tests the null hypothesis that the population median of all of the groups are equal. It is a non-parametric version of ANOVA. The test works on 2 or more independent samples, which may have different sizes. Note that rejecting the null hypothesis does not indicate which of the groups differs.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of the same population median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctKWPRtoLO = sstats.kruskal( np.array( OctPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( OctLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctKWPRtoLOPval = OctKWPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA have the same median is: %g\" % OctKWPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctKWPRtoBC = sstats.kruskal( np.array( OctPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( OctBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctKWPRtoBCPval = OctKWPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA have the same median is: %g\" % OctKWPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctKWLOtoBC = sstats.kruskal( np.array( OctLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( OctBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctKWLOtoBCPval = OctKWLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA have the same median is: %g\" % OctKWLOtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctLODF[\"Dry_Count\"].median(), OctBCDF[\"Dry_Count\"].median(), OctPRDF[\"Dry_Count\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OctPRQs = OctPRDF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "OctLOQs = OctLODF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "OctBCQs = OctBCDF[\"Dry_Count\"].quantile(q=nCompQs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxQs = max( OctPRQs.max(), OctLOQs.max(), OctBCQs.max() )\n",
    "maxQs = maxQs + 10.0\n",
    "maxQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( OctPRQs, OctLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( OctPRQs, OctBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( OctLOQs, OctBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('Oct Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, maxQs) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( OctPRQs, OctLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( OctPRQs, OctBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( OctLOQs, OctBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('Oct Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 20.0) )\n",
    "ax11.set_ylim( (0.0, 20.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.plot( OctPRQs, nCompQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM\")\n",
    "ax11.plot( OctLOQs, nCompQs, c='xkcd:grass green', marker='o', linestyle='-', label=\"CMIP5 - LOCA\")\n",
    "ax11.plot( OctBCQs, nCompQs, c='xkcd:dark orange', marker='o', linestyle='-', label=\"CMIP5 - BCCA\")\n",
    "ax11.set_title('Oct Empirical CDF', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, 1.1) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.1f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testS = np.array( [ x for x in range(1, int(maxQs) + 1, 1)], dtype=np.int32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRpmf = sstats.nbinom.pmf( testS, PRConvR, PRConvP )\n",
    "LOpmf = sstats.nbinom.pmf( testS, LOConvR, LOConvP )\n",
    "BCpmf = sstats.nbinom.pmf( testS, BCConvR, BCConvP )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.25\n",
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(10.0, 6.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "rects1 = ax11.bar( testS - (0.75*width), PRpmf, width, color=\"xkcd:royal blue\", label=\"PRISM\" )\n",
    "rects2 = ax11.bar( testS, LOpmf, width, color=\"xkcd:grass green\", label=\"LOCA\" )\n",
    "rects3 = ax11.bar( testS + (0.75*width), BCpmf, width, color=\"xkcd:dark orange\", label=\"BCCA\" )\n",
    "ax11.set_title('Oct Fitted Negative Binomial', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 30.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='upper right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.2f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some theoretical or fit parameters to use later for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovNum = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRConvP = PRDistDF.at[NovNum , HDRS[10]]\n",
    "PRConvR = PRDistDF.at[NovNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOConvP = LODistDF.at[NovNum , HDRS[10]]\n",
    "LOConvR = LODistDF.at[NovNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCConvP = BCDistDF.at[NovNum , HDRS[10]]\n",
    "BCConvR = BCDistDF.at[NovNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian estimates of confidence intervals for mean, variance, and standard deviation of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovPrBSCI = sstats.bayes_mvs( np.array( NovPRDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovPrBSCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovPrBSCI[0][0], NovPrBSCI[0][1][0], NovPrBSCI[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPRMean.append( NovPrBSCI[0][0] )\n",
    "SPRMeanMinCI.append( NovPrBSCI[0][1][0] )\n",
    "SPRMeanMaxCI.append( NovPrBSCI[0][1][1] )\n",
    "SPRVar.append( NovPrBSCI[1][0] )\n",
    "SPRVarMinCI.append( NovPrBSCI[1][1][0] )\n",
    "SPRVarMaxCI.append( NovPrBSCI[1][1][1] )\n",
    "SPRStd.append( NovPrBSCI[2][0] )\n",
    "SPRStdMinCI.append( NovPrBSCI[2][1][0] )\n",
    "SPRStdMaxCI.append( NovPrBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovLOBSCI = sstats.bayes_mvs( np.array( NovLODF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLOMean.append( NovLOBSCI[0][0] )\n",
    "SLOMeanMinCI.append( NovLOBSCI[0][1][0] )\n",
    "SLOMeanMaxCI.append( NovLOBSCI[0][1][1] )\n",
    "SLOVar.append( NovLOBSCI[1][0] )\n",
    "SLOVarMinCI.append( NovLOBSCI[1][1][0] )\n",
    "SLOVarMaxCI.append( NovLOBSCI[1][1][1] )\n",
    "SLOStd.append( NovLOBSCI[2][0] )\n",
    "SLOStdMinCI.append( NovLOBSCI[2][1][0] )\n",
    "SLOStdMaxCI.append( NovLOBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovBCBSCI = sstats.bayes_mvs( np.array( NovBCDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBCMean.append( NovBCBSCI[0][0] )\n",
    "SBCMeanMinCI.append( NovBCBSCI[0][1][0] )\n",
    "SBCMeanMaxCI.append( NovBCBSCI[0][1][1] )\n",
    "SBCVar.append( NovBCBSCI[1][0] )\n",
    "SBCVarMinCI.append( NovBCBSCI[1][1][0] )\n",
    "SBCVarMaxCI.append( NovBCBSCI[1][1][1] )\n",
    "SBCStd.append( NovBCBSCI[2][0] )\n",
    "SBCStdMinCI.append( NovBCBSCI[2][1][0] )\n",
    "SBCStdMaxCI.append( NovBCBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-Test for the means of two independent samples. Two-sided test for the null hypothesis that 2 independent samples hae identical average values. Test assumes that the populations have identical variances.\n",
    "\n",
    "If we observe a large p-value, for example larger than 0.05 or 0.1, then we cannot reject the null hypothesis of identical average scores. If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of equal averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovTTPRtoLO = sstats.ttest_ind( np.array( NovPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( NovLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovTTPRtoLOPval = NovTTPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same population is: %g\" % NovTTPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovTTPRtoBC = sstats.ttest_ind( np.array( NovPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( NovBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovTTPRtoBCPval = NovTTPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same population is: %g\" % NovTTPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovTTLOtoBC = sstats.ttest_ind( np.array( NovLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( NovBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovTTLOtoBCPval = NovTTLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same population is: %g\" % NovTTLOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mann-Whitney Rank Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonparametric test of the null hypothesis that it is equally likely that a randomly selected value from one sample will be less than or greater than a randomly selected value from a second sample. This test can be used to investigate whether two independent samples were selected from populations having the same distribution.\n",
    "\n",
    "Null hypothesis, $H_{0}$, is that the distributions of both populations are equal.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of being from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovMWUPRtoLO = sstats.mannwhitneyu( np.array( NovPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( NovLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovMWUPRtoLOPval = NovMWUPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same distribution is: %g\" % NovMWUPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovMWUPRtoBC = sstats.mannwhitneyu( np.array( NovPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( NovBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovMWUPRtoBCPval = NovMWUPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same distribution is: %g\" % NovMWUPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovMWULOtoBC = sstats.mannwhitneyu( np.array( NovLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( NovBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovMWULOtoBCPval = NovMWULOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same distribution is: %g\" % NovMWULOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kruskal-Wallis Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kruskal-Wallis H-test tests the null hypothesis that the population median of all of the groups are equal. It is a non-parametric version of ANOVA. The test works on 2 or more independent samples, which may have different sizes. Note that rejecting the null hypothesis does not indicate which of the groups differs.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of the same population median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovKWPRtoLO = sstats.kruskal( np.array( NovPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( NovLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovKWPRtoLOPval = NovKWPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA have the same median is: %g\" % NovKWPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovKWPRtoBC = sstats.kruskal( np.array( NovPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( NovBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovKWPRtoBCPval = NovKWPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA have the same median is: %g\" % NovKWPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovKWLOtoBC = sstats.kruskal( np.array( NovLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( NovBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovKWLOtoBCPval = NovKWLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA have the same median is: %g\" % NovKWLOtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovLODF[\"Dry_Count\"].median(), NovBCDF[\"Dry_Count\"].median(), NovPRDF[\"Dry_Count\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NovPRQs = NovPRDF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "NovLOQs = NovLODF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "NovBCQs = NovBCDF[\"Dry_Count\"].quantile(q=nCompQs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxQs = max( NovPRQs.max(), NovLOQs.max(), NovBCQs.max() )\n",
    "maxQs = maxQs + 10.0\n",
    "maxQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( NovPRQs, NovLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( NovPRQs, NovBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( NovLOQs, NovBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('Nov Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, maxQs) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( NovPRQs, NovLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( NovPRQs, NovBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( NovLOQs, NovBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('Nov Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 20.0) )\n",
    "ax11.set_ylim( (0.0, 20.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.plot( NovPRQs, nCompQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM\")\n",
    "ax11.plot( NovLOQs, nCompQs, c='xkcd:grass green', marker='o', linestyle='-', label=\"CMIP5 - LOCA\")\n",
    "ax11.plot( NovBCQs, nCompQs, c='xkcd:dark orange', marker='o', linestyle='-', label=\"CMIP5 - BCCA\")\n",
    "ax11.set_title('Nov Empirical CDF', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, 1.1) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.1f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testS = np.array( [ x for x in range(1, int(maxQs) + 1, 1)], dtype=np.int32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRpmf = sstats.nbinom.pmf( testS, PRConvR, PRConvP )\n",
    "LOpmf = sstats.nbinom.pmf( testS, LOConvR, LOConvP )\n",
    "BCpmf = sstats.nbinom.pmf( testS, BCConvR, BCConvP )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.25\n",
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(10.0, 6.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "rects1 = ax11.bar( testS - (0.75*width), PRpmf, width, color=\"xkcd:royal blue\", label=\"PRISM\" )\n",
    "rects2 = ax11.bar( testS, LOpmf, width, color=\"xkcd:grass green\", label=\"LOCA\" )\n",
    "rects3 = ax11.bar( testS + (0.75*width), BCpmf, width, color=\"xkcd:dark orange\", label=\"BCCA\" )\n",
    "ax11.set_title('Nov Fitted Negative Binomial', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 30.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='upper right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.2f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some theoretical or fit parameters to use later for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecNum = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRConvP = PRDistDF.at[DecNum , HDRS[10]]\n",
    "PRConvR = PRDistDF.at[DecNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOConvP = LODistDF.at[DecNum , HDRS[10]]\n",
    "LOConvR = LODistDF.at[DecNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCConvP = BCDistDF.at[DecNum , HDRS[10]]\n",
    "BCConvR = BCDistDF.at[DecNum , HDRS[11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian estimates of confidence intervals for mean, variance, and standard deviation of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecPrBSCI = sstats.bayes_mvs( np.array( DecPRDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecPrBSCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecPrBSCI[0][0], DecPrBSCI[0][1][0], DecPrBSCI[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPRMean.append( DecPrBSCI[0][0] )\n",
    "SPRMeanMinCI.append( DecPrBSCI[0][1][0] )\n",
    "SPRMeanMaxCI.append( DecPrBSCI[0][1][1] )\n",
    "SPRVar.append( DecPrBSCI[1][0] )\n",
    "SPRVarMinCI.append( DecPrBSCI[1][1][0] )\n",
    "SPRVarMaxCI.append( DecPrBSCI[1][1][1] )\n",
    "SPRStd.append( DecPrBSCI[2][0] )\n",
    "SPRStdMinCI.append( DecPrBSCI[2][1][0] )\n",
    "SPRStdMaxCI.append( DecPrBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecLOBSCI = sstats.bayes_mvs( np.array( DecLODF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLOMean.append( DecLOBSCI[0][0] )\n",
    "SLOMeanMinCI.append( DecLOBSCI[0][1][0] )\n",
    "SLOMeanMaxCI.append( DecLOBSCI[0][1][1] )\n",
    "SLOVar.append( DecLOBSCI[1][0] )\n",
    "SLOVarMinCI.append( DecLOBSCI[1][1][0] )\n",
    "SLOVarMaxCI.append( DecLOBSCI[1][1][1] )\n",
    "SLOStd.append( DecLOBSCI[2][0] )\n",
    "SLOStdMinCI.append( DecLOBSCI[2][1][0] )\n",
    "SLOStdMaxCI.append( DecLOBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecBCBSCI = sstats.bayes_mvs( np.array( DecBCDF[\"Dry_Count\"], dtype=np.int32 ), alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBCMean.append( DecBCBSCI[0][0] )\n",
    "SBCMeanMinCI.append( DecBCBSCI[0][1][0] )\n",
    "SBCMeanMaxCI.append( DecBCBSCI[0][1][1] )\n",
    "SBCVar.append( DecBCBSCI[1][0] )\n",
    "SBCVarMinCI.append( DecBCBSCI[1][1][0] )\n",
    "SBCVarMaxCI.append( DecBCBSCI[1][1][1] )\n",
    "SBCStd.append( DecBCBSCI[2][0] )\n",
    "SBCStdMinCI.append( DecBCBSCI[2][1][0] )\n",
    "SBCStdMaxCI.append( DecBCBSCI[2][1][1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-Test for the means of two independent samples. Two-sided test for the null hypothesis that 2 independent samples hae identical average values. Test assumes that the populations have identical variances.\n",
    "\n",
    "If we observe a large p-value, for example larger than 0.05 or 0.1, then we cannot reject the null hypothesis of identical average scores. If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of equal averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecTTPRtoLO = sstats.ttest_ind( np.array( DecPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( DecLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecTTPRtoLOPval = DecTTPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same population is: %g\" % DecTTPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecTTPRtoBC = sstats.ttest_ind( np.array( DecPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( DecBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecTTPRtoBCPval = DecTTPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same population is: %g\" % DecTTPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecTTLOtoBC = sstats.ttest_ind( np.array( DecLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                np.array( DecBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecTTLOtoBCPval = DecTTLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same population is: %g\" % DecTTLOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mann-Whitney Rank Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonparametric test of the null hypothesis that it is equally likely that a randomly selected value from one sample will be less than or greater than a randomly selected value from a second sample. This test can be used to investigate whether two independent samples were selected from populations having the same distribution.\n",
    "\n",
    "Null hypothesis, $H_{0}$, is that the distributions of both populations are equal.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of being from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecMWUPRtoLO = sstats.mannwhitneyu( np.array( DecPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( DecLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecMWUPRtoLOPval = DecMWUPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA from same distribution is: %g\" % DecMWUPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecMWUPRtoBC = sstats.mannwhitneyu( np.array( DecPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( DecBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecMWUPRtoBCPval = DecMWUPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA from same distribution is: %g\" % DecMWUPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecMWULOtoBC = sstats.mannwhitneyu( np.array( DecLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    np.array( DecBCDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                                    alternative='two-sided' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecMWULOtoBCPval = DecMWULOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA from same distribution is: %g\" % DecMWULOtoBCPval )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kruskal-Wallis Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kruskal-Wallis H-test tests the null hypothesis that the population median of all of the groups are equal. It is a non-parametric version of ANOVA. The test works on 2 or more independent samples, which may have different sizes. Note that rejecting the null hypothesis does not indicate which of the groups differs.\n",
    "\n",
    "If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of the same population median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecKWPRtoLO = sstats.kruskal( np.array( DecPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( DecLODF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecKWPRtoLOPval = DecKWPRtoLO[1]\n",
    "print(\"P-Value for PRISM and LOCA have the same median is: %g\" % DecKWPRtoLOPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecKWPRtoBC = sstats.kruskal( np.array( DecPRDF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( DecBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecKWPRtoBCPval = DecKWPRtoBC[1]\n",
    "print(\"P-Value for PRISM and BCCA have the same median is: %g\" % DecKWPRtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecKWLOtoBC = sstats.kruskal( np.array( DecLODF[\"Dry_Count\"], dtype=np.int32 ), \n",
    "                              np.array( DecBCDF[\"Dry_Count\"], dtype=np.int32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecKWLOtoBCPval = DecKWLOtoBC[1]\n",
    "print(\"P-Value for LOCA and BCCA have the same median is: %g\" % DecKWLOtoBCPval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecLODF[\"Dry_Count\"].median(), DecBCDF[\"Dry_Count\"].median(), DecPRDF[\"Dry_Count\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecPRQs = DecPRDF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "DecLOQs = DecLODF[\"Dry_Count\"].quantile(q=nCompQs)\n",
    "DecBCQs = DecBCDF[\"Dry_Count\"].quantile(q=nCompQs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxQs = max( DecPRQs.max(), DecLOQs.max(), DecBCQs.max() )\n",
    "maxQs = maxQs + 10.0\n",
    "maxQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( DecPRQs, DecLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( DecPRQs, DecBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( DecLOQs, DecBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('Dec Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, maxQs) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.scatter( DecPRQs, DecLOQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM - LOCA\")\n",
    "ax11.scatter( DecPRQs, DecBCQs, c='xkcd:grass green', marker='o', label=\"PRISM - BCCA\")\n",
    "ax11.scatter( DecLOQs, DecBCQs, c='xkcd:dark orange', marker='o', label=\"LOCA - BCCA\")\n",
    "ax11.plot( [0.0, maxQs], [0.0, maxQs], marker=None, linestyle='-', color='xkcd:slate', label=\"1:1\")\n",
    "ax11.set_title('Dec Comparison Q-Q Plot', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration, 1st (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Dry Spell Duration, 2nd (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 20.0) )\n",
    "ax11.set_ylim( (0.0, 20.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(8.0, 8.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.plot( DecPRQs, nCompQs, c='xkcd:royal blue', marker='o', linestyle='-', label=\"PRISM\")\n",
    "ax11.plot( DecLOQs, nCompQs, c='xkcd:grass green', marker='o', linestyle='-', label=\"CMIP5 - LOCA\")\n",
    "ax11.plot( DecBCQs, nCompQs, c='xkcd:dark orange', marker='o', linestyle='-', label=\"CMIP5 - BCCA\")\n",
    "ax11.set_title('Dec Empirical CDF', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, maxQs) )\n",
    "ax11.set_ylim( (0.0, 1.1) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='lower right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.1f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testS = np.array( [ x for x in range(1, int(maxQs) + 1, 1)], dtype=np.int32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRpmf = sstats.nbinom.pmf( testS, PRConvR, PRConvP )\n",
    "LOpmf = sstats.nbinom.pmf( testS, LOConvR, LOConvP )\n",
    "BCpmf = sstats.nbinom.pmf( testS, BCConvR, BCConvP )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.25\n",
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(10.0, 6.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "rects1 = ax11.bar( testS - (0.75*width), PRpmf, width, color=\"xkcd:royal blue\", label=\"PRISM\" )\n",
    "rects2 = ax11.bar( testS, LOpmf, width, color=\"xkcd:grass green\", label=\"LOCA\" )\n",
    "rects3 = ax11.bar( testS + (0.75*width), BCpmf, width, color=\"xkcd:dark orange\", label=\"BCCA\" )\n",
    "ax11.set_title('Dec Fitted Negative Binomial', fontsize=16 )\n",
    "ax11.set_xlabel('Dry Spell Duration (days)', fontsize=14 )\n",
    "ax11.set_ylabel('Probability', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 30.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='upper right')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.2f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Collations, Plots, and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataDict = { \"Min CI Mean\" : np.array( SPRMeanMinCI, dtype=np.float32 ), #0\n",
    "             \"Mean\" : np.array( SPRMean, dtype=np.float32 ), #1\n",
    "             \"Max CI Mean\" : np.array( SPRMeanMaxCI, dtype=np.float32 ), #2\n",
    "             \"Min CI Var\" : np.array( SPRVarMinCI, dtype=np.float32 ), #3\n",
    "             \"Var\" : np.array( SPRVar, dtype=np.float32 ), #4\n",
    "             \"Max CI Var\" : np.array( SPRVarMaxCI, dtype=np.float32 ), #5\n",
    "             \"Min CI Std\" : np.array( SPRStdMinCI, dtype=np.float32 ), #6\n",
    "             \"Std\" : np.array( SPRStd, dtype=np.float32 ), #7\n",
    "             \"Max CI Std\" : np.array( SPRStdMaxCI, dtype=np.float32 ), #8\n",
    "}\n",
    "PRBayStatsCIDF = pd.DataFrame( index=[x for x in range(1, 13, 1)], data=DataDict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSCIHds = list( PRBayStatsCIDF.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display( HTML( PRBayStatsCIDF.to_html() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataDict = { \"Min CI Mean\" : np.array( SLOMeanMinCI, dtype=np.float32 ), #0\n",
    "             \"Mean\" : np.array( SLOMean, dtype=np.float32 ), #1\n",
    "             \"Max CI Mean\" : np.array( SLOMeanMaxCI, dtype=np.float32 ), #2\n",
    "             \"Min CI Var\" : np.array( SLOVarMinCI, dtype=np.float32 ), #3\n",
    "             \"Var\" : np.array( SLOVar, dtype=np.float32 ), #4\n",
    "             \"Max CI Var\" : np.array( SLOVarMaxCI, dtype=np.float32 ), #5\n",
    "             \"Min CI Std\" : np.array( SLOStdMinCI, dtype=np.float32 ), #6\n",
    "             \"Std\" : np.array( SLOStd, dtype=np.float32 ), #7\n",
    "             \"Max CI Std\" : np.array( SLOStdMaxCI, dtype=np.float32 ), #8\n",
    "}\n",
    "LOBayStatsCIDF = pd.DataFrame( index=[x for x in range(1, 13, 1)], data=DataDict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display( HTML( LOBayStatsCIDF.to_html() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataDict = { \"Min CI Mean\" : np.array( SBCMeanMinCI, dtype=np.float32 ), #0\n",
    "             \"Mean\" : np.array( SBCMean, dtype=np.float32 ), #1\n",
    "             \"Max CI Mean\" : np.array( SBCMeanMaxCI, dtype=np.float32 ), #2\n",
    "             \"Min CI Var\" : np.array( SBCVarMinCI, dtype=np.float32 ), #3\n",
    "             \"Var\" : np.array( SBCVar, dtype=np.float32 ), #4\n",
    "             \"Max CI Var\" : np.array( SBCVarMaxCI, dtype=np.float32 ), #5\n",
    "             \"Min CI Std\" : np.array( SBCStdMinCI, dtype=np.float32 ), #6\n",
    "             \"Std\" : np.array( SBCStd, dtype=np.float32 ), #7\n",
    "             \"Max CI Std\" : np.array( SBCStdMaxCI, dtype=np.float32 ), #8\n",
    "}\n",
    "BCBayStatsCIDF = pd.DataFrame( index=[x for x in range(1, 13, 1)], data=DataDict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display( HTML( BCBayStatsCIDF.to_html() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"DryDayComp_1981-2011.xlsx\" ) )\n",
    "with pd.ExcelWriter( OutFiler ) as writer:\n",
    "    PRDistDF.to_excel( writer, sheet_name=\"PRISM\", na_rep=str(np.nan), columns=HDRS,\n",
    "                       index=False )\n",
    "    PRBayStatsCIDF.to_excel( writer, sheet_name=\"PRISM_CI_Stats\", na_rep=str(np.nan), \n",
    "                             columns=BSCIHds, index=True, index_label=\"Month\" )\n",
    "    LODistDF.to_excel( writer, sheet_name=\"LOCA\", na_rep=str(np.nan), columns=HDRS,\n",
    "                       index=False )\n",
    "    LOBayStatsCIDF.to_excel( writer, sheet_name=\"LOCA_CI_Stats\", na_rep=str(np.nan), \n",
    "                             columns=BSCIHds, index=True, index_label=\"Month\" )\n",
    "    BCDistDF.to_excel( writer, sheet_name=\"BCCA\", na_rep=str(np.nan), columns=HDRS,\n",
    "                       index=False )\n",
    "    BCBayStatsCIDF.to_excel( writer, sheet_name=\"BCCA_CI_Stats\", na_rep=str(np.nan), \n",
    "                             columns=BSCIHds, index=True, index_label=\"Month\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the monthly confidence intervals with statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRMeanCI = np.append( np.stack( [np.array(PRBayStatsCIDF.index, dtype=np.float32 ),\n",
    "                          np.array(PRBayStatsCIDF[BSCIHds[0]], dtype=np.float32 )],\n",
    "                          axis=1 ),\n",
    "                      np.stack( [np.flip(np.array(PRBayStatsCIDF.index, dtype=np.float32 ), 0),\n",
    "                          np.flip(np.array(PRBayStatsCIDF[BSCIHds[2]], dtype=np.float32 ), 0)],\n",
    "                          axis=1 ), axis=0 )\n",
    "PRMeanCI = np.vstack( [PRMeanCI[:,:], PRMeanCI[0,:]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOMeanCI = np.append( np.stack( [np.array(LOBayStatsCIDF.index, dtype=np.float32 ),\n",
    "                          np.array(LOBayStatsCIDF[BSCIHds[0]], dtype=np.float32 )],\n",
    "                          axis=1 ),\n",
    "                      np.stack( [np.flip(np.array(LOBayStatsCIDF.index, dtype=np.float32 ), 0),\n",
    "                          np.flip(np.array(LOBayStatsCIDF[BSCIHds[2]], dtype=np.float32 ), 0)],\n",
    "                          axis=1 ), axis=0 )\n",
    "LOMeanCI = np.vstack( [LOMeanCI[:,:], LOMeanCI[0,:]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCMeanCI = np.append( np.stack( [np.array(BCBayStatsCIDF.index, dtype=np.float32 ),\n",
    "                          np.array(BCBayStatsCIDF[BSCIHds[0]], dtype=np.float32 )],\n",
    "                          axis=1 ),\n",
    "                      np.stack( [np.flip(np.array(BCBayStatsCIDF.index, dtype=np.float32 ), 0),\n",
    "                          np.flip(np.array(BCBayStatsCIDF[BSCIHds[2]], dtype=np.float32 ), 0)],\n",
    "                          axis=1 ), axis=0 )\n",
    "BCMeanCI = np.vstack( [BCMeanCI[:,:], BCMeanCI[0,:]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(10.0, 6.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.plot( PRBayStatsCIDF.index, PRBayStatsCIDF[BSCIHds[1]], color=\"xkcd:royal blue\", \n",
    "           linestyle=\"-\", label=\"PRISM Mean\" )\n",
    "ax11.fill( PRMeanCI[:,0], PRMeanCI[:,1], color=\"xkcd:light blue\", alpha=0.5, \n",
    "           label=\"PRISM 90% CI\")\n",
    "ax11.plot( LOBayStatsCIDF.index, LOBayStatsCIDF[BSCIHds[1]], color=\"xkcd:grass green\", \n",
    "           linestyle=\"-\", label=\"LOCA Mean\" )\n",
    "ax11.fill( LOMeanCI[:,0], LOMeanCI[:,1], color=\"xkcd:sage\", alpha=0.5, \n",
    "           label=\"LOCA 90% CI\")\n",
    "ax11.plot( BCBayStatsCIDF.index, BCBayStatsCIDF[BSCIHds[1]], color=\"xkcd:dark orange\", \n",
    "           linestyle=\"-\", label=\"BCCA Mean\" )\n",
    "ax11.fill( BCMeanCI[:,0], BCMeanCI[:,1], color=\"xkcd:light orange\", alpha=0.5, \n",
    "           label=\"BCCA 90% CI\")\n",
    "ax11.set_title('Monthly Mean Comparison', fontsize=16 )\n",
    "ax11.set_xlabel('Month', fontsize=14 )\n",
    "ax11.set_ylabel('Mean Dry Spell Length (days)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 13.0) )\n",
    "ax11.set_ylim( (2.0, 12.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='upper left')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.1f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRVarCI = np.append( np.stack( [np.array(PRBayStatsCIDF.index, dtype=np.float32 ),\n",
    "                          np.array(PRBayStatsCIDF[BSCIHds[3]], dtype=np.float32 )],\n",
    "                          axis=1 ),\n",
    "                      np.stack( [np.flip(np.array(PRBayStatsCIDF.index, dtype=np.float32 ), 0),\n",
    "                          np.flip(np.array(PRBayStatsCIDF[BSCIHds[5]], dtype=np.float32 ), 0)],\n",
    "                          axis=1 ), axis=0 )\n",
    "PRVarCI = np.vstack( [PRVarCI[:,:], PRVarCI[0,:]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOVarCI = np.append( np.stack( [np.array(LOBayStatsCIDF.index, dtype=np.float32 ),\n",
    "                          np.array(LOBayStatsCIDF[BSCIHds[3]], dtype=np.float32 )],\n",
    "                          axis=1 ),\n",
    "                      np.stack( [np.flip(np.array(LOBayStatsCIDF.index, dtype=np.float32 ), 0),\n",
    "                          np.flip(np.array(LOBayStatsCIDF[BSCIHds[5]], dtype=np.float32 ), 0)],\n",
    "                          axis=1 ), axis=0 )\n",
    "LOVarCI = np.vstack( [LOVarCI[:,:], LOVarCI[0,:]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCVarCI = np.append( np.stack( [np.array(BCBayStatsCIDF.index, dtype=np.float32 ),\n",
    "                          np.array(BCBayStatsCIDF[BSCIHds[3]], dtype=np.float32 )],\n",
    "                          axis=1 ),\n",
    "                      np.stack( [np.flip(np.array(BCBayStatsCIDF.index, dtype=np.float32 ), 0),\n",
    "                          np.flip(np.array(BCBayStatsCIDF[BSCIHds[5]], dtype=np.float32 ), 0)],\n",
    "                          axis=1 ), axis=0 )\n",
    "BCVarCI = np.vstack( [BCVarCI[:,:], BCVarCI[0,:]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fig1 = plt.figure()\n",
    "Fig1.set_size_inches(10.0, 6.0)\n",
    "ax11 = Fig1.add_subplot(111)\n",
    "ax11.plot( PRBayStatsCIDF.index, PRBayStatsCIDF[BSCIHds[4]], color=\"xkcd:royal blue\", \n",
    "           linestyle=\"-\", label=\"PRISM Var\" )\n",
    "ax11.fill( PRVarCI[:,0], PRVarCI[:,1], color=\"xkcd:light blue\", alpha=0.5, \n",
    "           label=\"PRISM 90% CI\")\n",
    "ax11.plot( LOBayStatsCIDF.index, LOBayStatsCIDF[BSCIHds[4]], color=\"xkcd:grass green\", \n",
    "           linestyle=\"-\", label=\"LOCA Var\" )\n",
    "ax11.fill( LOVarCI[:,0], LOVarCI[:,1], color=\"xkcd:sage\", alpha=0.5, \n",
    "           label=\"LOCA 90% CI\")\n",
    "ax11.plot( BCBayStatsCIDF.index, BCBayStatsCIDF[BSCIHds[4]], color=\"xkcd:dark orange\", \n",
    "           linestyle=\"-\", label=\"BCCA Var\" )\n",
    "ax11.fill( BCVarCI[:,0], BCVarCI[:,1], color=\"xkcd:light orange\", alpha=0.5, \n",
    "           label=\"BCCA 90% CI\")\n",
    "ax11.set_title('Monthly Variance Comparison', fontsize=16 )\n",
    "ax11.set_xlabel('Month', fontsize=14 )\n",
    "ax11.set_ylabel('Variance of Dry Spell Length ($days^{2}$)', fontsize=14)\n",
    "ax11.set_xlim( (0.0, 13.0) )\n",
    "#ax11.set_ylim( (2.0, 12.0) )\n",
    "ax11.grid( b=True )\n",
    "ax11.legend(loc='upper left')\n",
    "ax11.tick_params(axis='both', which='major', labelsize=13)\n",
    "ax11.yaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.1f}\" ) )\n",
    "ax11.xaxis.set_major_formatter( mpl.ticker.StrMethodFormatter( \"{x:,.0f}\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
