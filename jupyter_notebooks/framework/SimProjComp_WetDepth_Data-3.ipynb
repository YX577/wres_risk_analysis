{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare WG Projected Precipitation Depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats as sstats\n",
    "import datetime as dt\n",
    "import sqlalchemy\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input information for weather generators\n",
    "WG_IN_DIR = r'C:\\Temp\\WG_Test_Out\\Test3\\Processed'\n",
    "OUT_DIR = r'C:\\Temp\\WG_Test_Out\\Test3\\Processed\\Comparison'\n",
    "OUT_ROOT = \"DC_WGMN3\"\n",
    "H1_DATA_ROOT = \"H1_Data_Depth_G\"\n",
    "H1_PROJ1_ROOT = \"H1P1_Depth_G\"\n",
    "H1_PROJ2_ROOT = \"H1P2_Depth_G\"\n",
    "H1_PROJ3_ROOT = \"H1P3_Depth_G\"\n",
    "PLOT_DIR = \"Plots_ProjComp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCA_KEYS = [ 62, 63, 64, 76, 77, 78, 79, 90, 91, 92, 93, 94,\n",
    "              104, 105, 106, 107, 108, 120, 121, 122, 123, 137 ]\n",
    "NUM_LOCA_GRID = len( LOCA_KEYS )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start working with the data period.\n",
    "Load all grid cells and concatenate from the WG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFList = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gG in LOCA_KEYS:\n",
    "    cFile = \"%s%d.pickle\" % ( H1_DATA_ROOT, gG )\n",
    "    InFP = os.path.normpath( os.path.join( WG_IN_DIR, cFile ) )\n",
    "    cDF = pd.read_pickle( InFP )\n",
    "    cDF['Grid_Id'] = gG\n",
    "    cDF.drop( columns=['Year', 'Day'], inplace=True )\n",
    "    DFList.append( cDF )\n",
    "# end of for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumDF = len( DFList )\n",
    "NumDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "H1Data = pd.concat( DFList, ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>PDepth_mm</th>\n",
       "      <th>Grid_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.903307</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11.131537</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5.670500</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4.555808</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3.614461</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( HTML( H1Data.head().to_html() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can now drop some columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now filter all into monthly values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "H1DJanDF = H1Data[H1Data['Month'] == 1].copy()\n",
    "H1DFebDF = H1Data[H1Data['Month'] == 2].copy()\n",
    "H1DMarDF = H1Data[H1Data['Month'] == 3].copy()\n",
    "H1DAprDF = H1Data[H1Data['Month'] == 4].copy()\n",
    "H1DMayDF = H1Data[H1Data['Month'] == 5].copy()\n",
    "H1DJunDF = H1Data[H1Data['Month'] == 6].copy()\n",
    "H1DJulDF = H1Data[H1Data['Month'] == 7].copy()\n",
    "H1DAugDF = H1Data[H1Data['Month'] == 8].copy()\n",
    "H1DSepDF = H1Data[H1Data['Month'] == 9].copy()\n",
    "H1DOctDF = H1Data[H1Data['Month'] == 10].copy()\n",
    "H1DNovDF = H1Data[H1Data['Month'] == 11].copy()\n",
    "H1DDecDF = H1Data[H1Data['Month'] == 12].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del H1Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MonthLister = [ \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \n",
    "                 \"Sep\", \"Oct\", \"Nov\", \"Dec\" ]\n",
    "AveLister = list()\n",
    "VarLister = list()\n",
    "SkewLister = list()\n",
    "KurtLister = list()\n",
    "CntLister = list()\n",
    "MedianLister = list()\n",
    "MaxLister = list()\n",
    "MinLister = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.95, 0.96, 0.97, 0.98, 0.99, 0.995, 0.999, 0.9999, 1.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OurQList = [ round( 0.01 * x, 2 ) for x in range(100) ]\n",
    "OurQList.append( 0.995 )\n",
    "OurQList.append( 0.999 )\n",
    "OurQList.append( 0.9999 )\n",
    "OurQList.append( 1.0 )\n",
    "OurQList[95:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OurQs = np.array( OurQList, dtype=np.float32 )\n",
    "NumQs = len( OurQs )\n",
    "NumQs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Dataset Quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataDict = { MonthLister[0] : np.array( H1DJanDF['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ),\n",
    "             MonthLister[1] : np.array( H1DFebDF['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ),\n",
    "             MonthLister[2] : np.array( H1DMarDF['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ),\n",
    "             MonthLister[3] : np.array( H1DAprDF['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ),\n",
    "             MonthLister[4] : np.array( H1DMayDF['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ),\n",
    "             MonthLister[5] : np.array( H1DJunDF['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ),\n",
    "             MonthLister[6] : np.array( H1DJulDF['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ),\n",
    "             MonthLister[7] : np.array( H1DAugDF['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ),\n",
    "             MonthLister[8] : np.array( H1DSepDF['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ),\n",
    "             MonthLister[9] : np.array( H1DOctDF['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ),\n",
    "             MonthLister[10] : np.array( H1DNovDF['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ),\n",
    "             MonthLister[11] : np.array( H1DDecDF['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ), }\n",
    "H1DataMonthsPDF = pd.DataFrame( index=OurQs, data=DataDict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "AveLister = [ [ H1DJanDF['PDepth_mm'].mean() ],\n",
    "              [ H1DFebDF['PDepth_mm'].mean() ],\n",
    "              [ H1DMarDF['PDepth_mm'].mean() ],\n",
    "              [ H1DAprDF['PDepth_mm'].mean() ],\n",
    "              [ H1DMayDF['PDepth_mm'].mean() ],\n",
    "              [ H1DJunDF['PDepth_mm'].mean() ],\n",
    "              [ H1DJulDF['PDepth_mm'].mean() ],\n",
    "              [ H1DAugDF['PDepth_mm'].mean() ],\n",
    "              [ H1DSepDF['PDepth_mm'].mean() ],\n",
    "              [ H1DOctDF['PDepth_mm'].mean() ],\n",
    "              [ H1DNovDF['PDepth_mm'].mean() ],\n",
    "              [ H1DDecDF['PDepth_mm'].mean() ],\n",
    "            ]\n",
    "MedianLister = [ [ H1DJanDF['PDepth_mm'].median() ],\n",
    "              [ H1DFebDF['PDepth_mm'].median() ],\n",
    "              [ H1DMarDF['PDepth_mm'].median() ],\n",
    "              [ H1DAprDF['PDepth_mm'].median() ],\n",
    "              [ H1DMayDF['PDepth_mm'].median() ],\n",
    "              [ H1DJunDF['PDepth_mm'].median() ],\n",
    "              [ H1DJulDF['PDepth_mm'].median() ],\n",
    "              [ H1DAugDF['PDepth_mm'].median() ],\n",
    "              [ H1DSepDF['PDepth_mm'].median() ],\n",
    "              [ H1DOctDF['PDepth_mm'].median() ],\n",
    "              [ H1DNovDF['PDepth_mm'].median() ],\n",
    "              [ H1DDecDF['PDepth_mm'].median() ],\n",
    "            ]\n",
    "MaxLister = [ [ H1DJanDF['PDepth_mm'].max() ],\n",
    "              [ H1DFebDF['PDepth_mm'].max() ],\n",
    "              [ H1DMarDF['PDepth_mm'].max() ],\n",
    "              [ H1DAprDF['PDepth_mm'].max() ],\n",
    "              [ H1DMayDF['PDepth_mm'].max() ],\n",
    "              [ H1DJunDF['PDepth_mm'].max() ],\n",
    "              [ H1DJulDF['PDepth_mm'].max() ],\n",
    "              [ H1DAugDF['PDepth_mm'].max() ],\n",
    "              [ H1DSepDF['PDepth_mm'].max() ],\n",
    "              [ H1DOctDF['PDepth_mm'].max() ],\n",
    "              [ H1DNovDF['PDepth_mm'].max() ],\n",
    "              [ H1DDecDF['PDepth_mm'].max() ],\n",
    "            ]\n",
    "MinLister = [ [ H1DJanDF['PDepth_mm'].min() ],\n",
    "              [ H1DFebDF['PDepth_mm'].min() ],\n",
    "              [ H1DMarDF['PDepth_mm'].min() ],\n",
    "              [ H1DAprDF['PDepth_mm'].min() ],\n",
    "              [ H1DMayDF['PDepth_mm'].min() ],\n",
    "              [ H1DJunDF['PDepth_mm'].min() ],\n",
    "              [ H1DJulDF['PDepth_mm'].min() ],\n",
    "              [ H1DAugDF['PDepth_mm'].min() ],\n",
    "              [ H1DSepDF['PDepth_mm'].min() ],\n",
    "              [ H1DOctDF['PDepth_mm'].min() ],\n",
    "              [ H1DNovDF['PDepth_mm'].min() ],\n",
    "              [ H1DDecDF['PDepth_mm'].min() ],\n",
    "            ]\n",
    "VarLister = [ [ H1DJanDF['PDepth_mm'].var() ],\n",
    "              [ H1DFebDF['PDepth_mm'].var() ],\n",
    "              [ H1DMarDF['PDepth_mm'].var() ],\n",
    "              [ H1DAprDF['PDepth_mm'].var() ],\n",
    "              [ H1DMayDF['PDepth_mm'].var() ],\n",
    "              [ H1DJunDF['PDepth_mm'].var() ],\n",
    "              [ H1DJulDF['PDepth_mm'].var()],\n",
    "              [ H1DAugDF['PDepth_mm'].var() ],\n",
    "              [ H1DSepDF['PDepth_mm'].var() ],\n",
    "              [ H1DOctDF['PDepth_mm'].var() ],\n",
    "              [ H1DNovDF['PDepth_mm'].var() ],\n",
    "              [ H1DDecDF['PDepth_mm'].var() ],\n",
    "            ]\n",
    "SkewLister = [ [ H1DJanDF['PDepth_mm'].skew() ],\n",
    "              [ H1DFebDF['PDepth_mm'].skew() ],\n",
    "              [ H1DMarDF['PDepth_mm'].skew() ],\n",
    "              [ H1DAprDF['PDepth_mm'].skew() ],\n",
    "              [ H1DMayDF['PDepth_mm'].skew() ],\n",
    "              [ H1DJunDF['PDepth_mm'].skew() ],\n",
    "              [ H1DJulDF['PDepth_mm'].skew() ],\n",
    "              [ H1DAugDF['PDepth_mm'].skew() ],\n",
    "              [ H1DSepDF['PDepth_mm'].skew() ],\n",
    "              [ H1DOctDF['PDepth_mm'].skew() ],\n",
    "              [ H1DNovDF['PDepth_mm'].skew() ],\n",
    "              [ H1DDecDF['PDepth_mm'].skew() ],\n",
    "            ]\n",
    "KurtLister = [ [ H1DJanDF['PDepth_mm'].kurtosis() ],\n",
    "              [ H1DFebDF['PDepth_mm'].kurtosis() ],\n",
    "              [ H1DMarDF['PDepth_mm'].kurtosis() ],\n",
    "              [ H1DAprDF['PDepth_mm'].kurtosis() ],\n",
    "              [ H1DMayDF['PDepth_mm'].kurtosis() ],\n",
    "              [ H1DJunDF['PDepth_mm'].kurtosis() ],\n",
    "              [ H1DJulDF['PDepth_mm'].kurtosis() ],\n",
    "              [ H1DAugDF['PDepth_mm'].kurtosis() ],\n",
    "              [ H1DSepDF['PDepth_mm'].kurtosis() ],\n",
    "              [ H1DOctDF['PDepth_mm'].kurtosis() ],\n",
    "              [ H1DNovDF['PDepth_mm'].kurtosis() ],\n",
    "              [ H1DDecDF['PDepth_mm'].kurtosis() ],\n",
    "            ]\n",
    "CntLister = [ [ H1DJanDF['PDepth_mm'].count() ],\n",
    "              [ H1DFebDF['PDepth_mm'].count() ],\n",
    "              [ H1DMarDF['PDepth_mm'].count() ],\n",
    "              [ H1DAprDF['PDepth_mm'].count() ],\n",
    "              [ H1DMayDF['PDepth_mm'].count() ],\n",
    "              [ H1DJunDF['PDepth_mm'].count() ],\n",
    "              [ H1DJulDF['PDepth_mm'].count() ],\n",
    "              [ H1DAugDF['PDepth_mm'].count() ],\n",
    "              [ H1DSepDF['PDepth_mm'].count() ],\n",
    "              [ H1DOctDF['PDepth_mm'].count() ],\n",
    "              [ H1DNovDF['PDepth_mm'].count() ],\n",
    "              [ H1DDecDF['PDepth_mm'].count() ],\n",
    "            ]\n",
    "# process stats to dataframe\n",
    "DataDict = dict()\n",
    "DataDict[\"H1D_Ave\"] = np.array( [x[0] for x in AveLister], np.float32 )\n",
    "DataDict[\"H1D_Med\"] = np.array( [x[0] for x in MedianLister], np.float32 )\n",
    "DataDict[\"H1D_Max\"] = np.array( [x[0] for x in MaxLister], np.float32 )\n",
    "DataDict[\"H1D_Min\"] = np.array( [x[0] for x in MinLister], np.float32 )   \n",
    "DataDict[\"H1D_Var\"] = np.array( [x[0] for x in VarLister], np.float32 )\n",
    "DataDict[\"H1D_Skew\"] = np.array( [x[0] for x in SkewLister], np.float32 )\n",
    "DataDict[\"H1D_Kurt\"] = np.array( [x[0] for x in KurtLister], np.float32 )\n",
    "DataDict[\"H1D_Cnt\"] = np.array( [x[0] for x in CntLister], np.float32 )\n",
    "SumCompDF = pd.DataFrame( index=MonthLister, data=DataDict )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "OutFileFP = os.path.normpath( os.path.join( OUT_DIR, \"%s_WG_PDepth_Projections.xlsx\" % OUT_ROOT ) )\n",
    "with pd.ExcelWriter( OutFileFP, engine=\"openpyxl\", mode='w' ) as writer:\n",
    "    SumCompDF.to_excel( writer, sheet_name=\"H1D_Summary\" )\n",
    "    H1DataMonthsPDF.to_excel( writer, sheet_name=\"H1Data_ptiles\" )\n",
    "# end of with block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Grid Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now need to create some data structures so that can do our processing and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "H1DDict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gG in LOCA_KEYS:\n",
    "    InnerDD = dict()\n",
    "    # now manually assign\n",
    "    InnerDD[1] = H1DJanDF[H1DJanDF['Grid_Id'] == gG].copy()\n",
    "    InnerDD[2] = H1DFebDF[H1DFebDF['Grid_Id'] == gG].copy()\n",
    "    InnerDD[3] = H1DMarDF[H1DMarDF['Grid_Id'] == gG].copy()\n",
    "    InnerDD[4] = H1DAprDF[H1DAprDF['Grid_Id'] == gG].copy()\n",
    "    InnerDD[5] = H1DMayDF[H1DMayDF['Grid_Id'] == gG].copy()\n",
    "    InnerDD[6] = H1DJunDF[H1DJunDF['Grid_Id'] == gG].copy()\n",
    "    InnerDD[7] = H1DJulDF[H1DJulDF['Grid_Id'] == gG].copy()\n",
    "    InnerDD[8] = H1DAugDF[H1DAugDF['Grid_Id'] == gG].copy()\n",
    "    InnerDD[9] = H1DSepDF[H1DSepDF['Grid_Id'] == gG].copy()\n",
    "    InnerDD[10] = H1DOctDF[H1DOctDF['Grid_Id'] == gG].copy()\n",
    "    InnerDD[11] = H1DNovDF[H1DNovDF['Grid_Id'] == gG].copy()\n",
    "    InnerDD[12] = H1DDecDF[H1DDecDF['Grid_Id'] == gG].copy()\n",
    "    # now assign to our grid dictionary\n",
    "    H1DDict[gG] = InnerDD\n",
    "# end of outer for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the month arrays\n",
    "OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_Jan.pickle\" % OUT_ROOT ) )\n",
    "with open( OutFiler, 'wb' ) as OuP:\n",
    "    pickle.dump( H1DJanDF, OuP, protocol=pickle.HIGHEST_PROTOCOL )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the month arrays\n",
    "OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_Feb.pickle\" % OUT_ROOT ) )\n",
    "with open( OutFiler, 'wb' ) as OuP:\n",
    "    pickle.dump( H1DFebDF, OuP, protocol=pickle.HIGHEST_PROTOCOL )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the month arrays\n",
    "OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_Mar.pickle\" % OUT_ROOT ) )\n",
    "with open( OutFiler, 'wb' ) as OuP:\n",
    "    pickle.dump( H1DMarDF, OuP, protocol=pickle.HIGHEST_PROTOCOL )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the month arrays\n",
    "OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_Apr.pickle\" % OUT_ROOT ) )\n",
    "with open( OutFiler, 'wb' ) as OuP:\n",
    "    pickle.dump( H1DAprDF, OuP, protocol=pickle.HIGHEST_PROTOCOL )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the month arrays\n",
    "OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_May.pickle\" % OUT_ROOT ) )\n",
    "with open( OutFiler, 'wb' ) as OuP:\n",
    "    pickle.dump( H1DMayDF, OuP, protocol=pickle.HIGHEST_PROTOCOL )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the month arrays\n",
    "OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_Jun.pickle\" % OUT_ROOT ) )\n",
    "with open( OutFiler, 'wb' ) as OuP:\n",
    "    pickle.dump( H1DJunDF, OuP, protocol=pickle.HIGHEST_PROTOCOL )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the month arrays\n",
    "OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_Jul.pickle\" % OUT_ROOT ) )\n",
    "with open( OutFiler, 'wb' ) as OuP:\n",
    "    pickle.dump( H1DJulDF, OuP, protocol=pickle.HIGHEST_PROTOCOL )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the month arrays\n",
    "OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_Aug.pickle\" % OUT_ROOT ) )\n",
    "with open( OutFiler, 'wb' ) as OuP:\n",
    "    pickle.dump( H1DAugDF, OuP, protocol=pickle.HIGHEST_PROTOCOL )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the month arrays\n",
    "OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_Sep.pickle\" % OUT_ROOT ) )\n",
    "with open( OutFiler, 'wb' ) as OuP:\n",
    "    pickle.dump( H1DSepDF, OuP, protocol=pickle.HIGHEST_PROTOCOL )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the month arrays\n",
    "OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_Oct.pickle\" % OUT_ROOT ) )\n",
    "with open( OutFiler, 'wb' ) as OuP:\n",
    "    pickle.dump( H1DOctDF, OuP, protocol=pickle.HIGHEST_PROTOCOL )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the month arrays\n",
    "OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_Nov.pickle\" % OUT_ROOT ) )\n",
    "with open( OutFiler, 'wb' ) as OuP:\n",
    "    pickle.dump( H1DNovDF, OuP, protocol=pickle.HIGHEST_PROTOCOL )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the month arrays\n",
    "OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_Dec.pickle\" % OUT_ROOT ) )\n",
    "with open( OutFiler, 'wb' ) as OuP:\n",
    "    pickle.dump( H1DDecDF, OuP, protocol=pickle.HIGHEST_PROTOCOL )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "del H1DJanDF\n",
    "del H1DFebDF\n",
    "del H1DMarDF\n",
    "del H1DAprDF\n",
    "del H1DMayDF\n",
    "del H1DJunDF\n",
    "del H1DJulDF\n",
    "del H1DAugDF\n",
    "del H1DSepDF\n",
    "del H1DOctDF\n",
    "del H1DNovDF\n",
    "del H1DDecDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collate the monthly statistics and output to a spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gG in LOCA_KEYS:\n",
    "    # initialize our lists\n",
    "    AveLister = list()\n",
    "    VarLister = list()\n",
    "    SkewLister = list()\n",
    "    KurtLister = list()\n",
    "    CntLister = list()\n",
    "    MeanLister = list()\n",
    "    MaxLister = list()\n",
    "    MinLister = list()\n",
    "    # H1 data\n",
    "    gDDict = H1DDict[gG]\n",
    "    DataDict = { MonthLister[0] : np.array( gDDict[1]['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ),\n",
    "                 MonthLister[1] : np.array( gDDict[2]['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ),\n",
    "                 MonthLister[2] : np.array( gDDict[3]['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ),\n",
    "                 MonthLister[3] : np.array( gDDict[4]['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ),\n",
    "                 MonthLister[4] : np.array( gDDict[5]['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ),\n",
    "                 MonthLister[5] : np.array( gDDict[6]['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ),\n",
    "                 MonthLister[6] : np.array( gDDict[7]['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ),\n",
    "                 MonthLister[7] : np.array( gDDict[8]['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ),\n",
    "                 MonthLister[8] : np.array( gDDict[9]['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ),\n",
    "                 MonthLister[9] : np.array( gDDict[10]['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ),\n",
    "                 MonthLister[10] : np.array( gDDict[11]['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ),\n",
    "                 MonthLister[11] : np.array( gDDict[12]['PDepth_mm'].quantile(q=OurQs), dtype=np.float64 ), }\n",
    "    DaQsDF = pd.DataFrame( index=OurQs, data=DataDict )\n",
    "    # do our stats\n",
    "    # mean\n",
    "    AveLister = [ [ gDDict[1]['PDepth_mm'].mean() ],\n",
    "                  [ gDDict[2]['PDepth_mm'].mean() ],\n",
    "                  [ gDDict[3]['PDepth_mm'].mean() ],\n",
    "                  [ gDDict[4]['PDepth_mm'].mean() ],\n",
    "                  [ gDDict[5]['PDepth_mm'].mean() ],\n",
    "                  [ gDDict[6]['PDepth_mm'].mean() ],\n",
    "                  [ gDDict[7]['PDepth_mm'].mean() ],\n",
    "                  [ gDDict[8]['PDepth_mm'].mean() ],\n",
    "                  [ gDDict[9]['PDepth_mm'].mean() ],\n",
    "                  [ gDDict[10]['PDepth_mm'].mean() ],\n",
    "                  [ gDDict[11]['PDepth_mm'].mean() ],\n",
    "                  [ gDDict[12]['PDepth_mm'].mean() ],\n",
    "                ]\n",
    "    # median\n",
    "    MedianLister = [ [ gDDict[1]['PDepth_mm'].median() ],\n",
    "                  [ gDDict[2]['PDepth_mm'].median() ],\n",
    "                  [ gDDict[3]['PDepth_mm'].median() ],\n",
    "                  [ gDDict[4]['PDepth_mm'].median() ],\n",
    "                  [ gDDict[5]['PDepth_mm'].median() ],\n",
    "                  [ gDDict[6]['PDepth_mm'].median() ],\n",
    "                  [ gDDict[7]['PDepth_mm'].median() ],\n",
    "                  [ gDDict[8]['PDepth_mm'].median() ],\n",
    "                  [ gDDict[9]['PDepth_mm'].median() ],\n",
    "                  [ gDDict[10]['PDepth_mm'].median() ],\n",
    "                  [ gDDict[11]['PDepth_mm'].median() ],\n",
    "                  [ gDDict[12]['PDepth_mm'].median() ],\n",
    "                ]\n",
    "    # max\n",
    "    MaxLister = [ [ gDDict[1]['PDepth_mm'].max() ],\n",
    "                  [ gDDict[2]['PDepth_mm'].max() ],\n",
    "                  [ gDDict[3]['PDepth_mm'].max() ],\n",
    "                  [ gDDict[4]['PDepth_mm'].max() ],\n",
    "                  [ gDDict[5]['PDepth_mm'].max() ],\n",
    "                  [ gDDict[6]['PDepth_mm'].max() ],\n",
    "                  [ gDDict[7]['PDepth_mm'].max() ],\n",
    "                  [ gDDict[8]['PDepth_mm'].max() ],\n",
    "                  [ gDDict[9]['PDepth_mm'].max() ],\n",
    "                  [ gDDict[10]['PDepth_mm'].max() ],\n",
    "                  [ gDDict[11]['PDepth_mm'].max() ],\n",
    "                  [ gDDict[12]['PDepth_mm'].max() ],\n",
    "                ]\n",
    "    # min\n",
    "    MinLister = [ [ gDDict[1]['PDepth_mm'].min() ],\n",
    "                  [ gDDict[2]['PDepth_mm'].min() ],\n",
    "                  [ gDDict[3]['PDepth_mm'].min() ],\n",
    "                  [ gDDict[4]['PDepth_mm'].min() ],\n",
    "                  [ gDDict[5]['PDepth_mm'].min() ],\n",
    "                  [ gDDict[6]['PDepth_mm'].min() ],\n",
    "                  [ gDDict[7]['PDepth_mm'].min() ],\n",
    "                  [ gDDict[8]['PDepth_mm'].min() ],\n",
    "                  [ gDDict[9]['PDepth_mm'].min() ],\n",
    "                  [ gDDict[10]['PDepth_mm'].min() ],\n",
    "                  [ gDDict[11]['PDepth_mm'].min() ],\n",
    "                  [ gDDict[12]['PDepth_mm'].min() ],\n",
    "                ]\n",
    "    # variance\n",
    "    VarLister = [ [ gDDict[1]['PDepth_mm'].var() ],\n",
    "                  [ gDDict[2]['PDepth_mm'].var() ],\n",
    "                  [ gDDict[3]['PDepth_mm'].var() ],\n",
    "                  [ gDDict[4]['PDepth_mm'].var() ],\n",
    "                  [ gDDict[5]['PDepth_mm'].var() ],\n",
    "                  [ gDDict[6]['PDepth_mm'].var() ],\n",
    "                  [ gDDict[7]['PDepth_mm'].var() ],\n",
    "                  [ gDDict[8]['PDepth_mm'].var() ],\n",
    "                  [ gDDict[9]['PDepth_mm'].var() ],\n",
    "                  [ gDDict[10]['PDepth_mm'].var() ],\n",
    "                  [ gDDict[11]['PDepth_mm'].var() ],\n",
    "                  [ gDDict[12]['PDepth_mm'].var() ],\n",
    "                ]\n",
    "    # skew\n",
    "    SkewLister = [ [ gDDict[1]['PDepth_mm'].skew() ],\n",
    "                  [ gDDict[2]['PDepth_mm'].skew() ],\n",
    "                  [ gDDict[3]['PDepth_mm'].skew() ],\n",
    "                  [ gDDict[4]['PDepth_mm'].skew() ],\n",
    "                  [ gDDict[5]['PDepth_mm'].skew() ],\n",
    "                  [ gDDict[6]['PDepth_mm'].skew() ],\n",
    "                  [ gDDict[7]['PDepth_mm'].skew() ],\n",
    "                  [ gDDict[8]['PDepth_mm'].skew() ],\n",
    "                  [ gDDict[9]['PDepth_mm'].skew() ],\n",
    "                  [ gDDict[10]['PDepth_mm'].skew() ],\n",
    "                  [ gDDict[11]['PDepth_mm'].skew() ],\n",
    "                  [ gDDict[12]['PDepth_mm'].skew() ],\n",
    "                ]\n",
    "    # kurtosis\n",
    "    KurtLister = [ [ gDDict[1]['PDepth_mm'].kurtosis() ],\n",
    "                  [ gDDict[2]['PDepth_mm'].kurtosis() ],\n",
    "                  [ gDDict[3]['PDepth_mm'].kurtosis() ],\n",
    "                  [ gDDict[4]['PDepth_mm'].kurtosis() ],\n",
    "                  [ gDDict[5]['PDepth_mm'].kurtosis() ],\n",
    "                  [ gDDict[6]['PDepth_mm'].kurtosis() ],\n",
    "                  [ gDDict[7]['PDepth_mm'].kurtosis() ],\n",
    "                  [ gDDict[8]['PDepth_mm'].kurtosis() ],\n",
    "                  [ gDDict[9]['PDepth_mm'].kurtosis() ],\n",
    "                  [ gDDict[10]['PDepth_mm'].kurtosis() ],\n",
    "                  [ gDDict[11]['PDepth_mm'].kurtosis() ],\n",
    "                  [ gDDict[12]['PDepth_mm'].kurtosis() ],\n",
    "                ]\n",
    "    # counts\n",
    "    CntLister = [ [ gDDict[1]['PDepth_mm'].count() ],\n",
    "                  [ gDDict[2]['PDepth_mm'].count() ],\n",
    "                  [ gDDict[3]['PDepth_mm'].count() ],\n",
    "                  [ gDDict[4]['PDepth_mm'].count() ],\n",
    "                  [ gDDict[5]['PDepth_mm'].count() ],\n",
    "                  [ gDDict[6]['PDepth_mm'].count() ],\n",
    "                  [ gDDict[7]['PDepth_mm'].count() ],\n",
    "                  [ gDDict[8]['PDepth_mm'].count() ],\n",
    "                  [ gDDict[9]['PDepth_mm'].count() ],\n",
    "                  [ gDDict[10]['PDepth_mm'].count() ],\n",
    "                  [ gDDict[11]['PDepth_mm'].count() ],\n",
    "                  [ gDDict[12]['PDepth_mm'].count() ],\n",
    "                ]\n",
    "    # process stats to dataframe\n",
    "    DataDict = dict()\n",
    "    DataDict[\"H1D_Ave\"] = np.array( [x[0] for x in AveLister], np.float32 )\n",
    "    DataDict[\"H1D_Med\"] = np.array( [x[0] for x in MedianLister], np.float32 )\n",
    "    DataDict[\"H1D_Max\"] = np.array( [x[0] for x in MaxLister], np.float32 )\n",
    "    DataDict[\"H1D_Min\"] = np.array( [x[0] for x in MinLister], np.float32 )  \n",
    "    DataDict[\"H1D_Var\"] = np.array( [x[0] for x in VarLister], np.float32 )\n",
    "    DataDict[\"H1D_Skew\"] = np.array( [x[0] for x in SkewLister], np.float32 )\n",
    "    DataDict[\"H1D_Kurt\"] = np.array( [x[0] for x in KurtLister], np.float32 )\n",
    "    DataDict[\"H1D_Cnt\"] = np.array( [x[0] for x in CntLister], np.float32 )\n",
    "    SumCompDF = pd.DataFrame( index=MonthLister, data=DataDict )\n",
    "    # now write out to a spreadsheet\n",
    "    OutFileFP = os.path.normpath( os.path.join( OUT_DIR, \"%s_WG_PDepth_Proj_G%d.xlsx\" % (OUT_ROOT, gG) ) )\n",
    "    with pd.ExcelWriter( OutFileFP, engine=\"openpyxl\" ) as writer:\n",
    "        SumCompDF.to_excel( writer, sheet_name=\"H1D_Summary\" )\n",
    "        DaQsDF.to_excel( writer, sheet_name=\"H1_Data\" )\n",
    "    # end of with\n",
    "# end of for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save out pickle files so that can do the plotting in a different notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gG in LOCA_KEYS:\n",
    "    OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_G%d_1.pickle\" % (OUT_ROOT, gG) ) )\n",
    "    H1DDict[gG][1].to_pickle( OutFiler, compression='zip' )\n",
    "    OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_G%d_2.pickle\" % (OUT_ROOT, gG) ) )\n",
    "    H1DDict[gG][2].to_pickle( OutFiler, compression='zip' )\n",
    "    OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_G%d_3.pickle\" % (OUT_ROOT, gG) ) )\n",
    "    H1DDict[gG][3].to_pickle( OutFiler, compression='zip' )\n",
    "    OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_G%d_4.pickle\" % (OUT_ROOT, gG) ) )\n",
    "    H1DDict[gG][4].to_pickle( OutFiler, compression='zip' )\n",
    "    OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_G%d_5.pickle\" % (OUT_ROOT, gG) ) )\n",
    "    H1DDict[gG][5].to_pickle( OutFiler, compression='zip' )\n",
    "    OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_G%d_6.pickle\" % (OUT_ROOT, gG) ) )\n",
    "    H1DDict[gG][6].to_pickle( OutFiler, compression='zip' )\n",
    "    OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_G%d_7.pickle\" % (OUT_ROOT, gG) ) )\n",
    "    H1DDict[gG][7].to_pickle( OutFiler, compression='zip' )\n",
    "    OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_G%d_8.pickle\" % (OUT_ROOT, gG) ) )\n",
    "    H1DDict[gG][8].to_pickle( OutFiler, compression='zip' )\n",
    "    OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_G%d_9.pickle\" % (OUT_ROOT, gG) ) )\n",
    "    H1DDict[gG][9].to_pickle( OutFiler, compression='zip' )\n",
    "    OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_G%d_10.pickle\" % (OUT_ROOT, gG) ) )\n",
    "    H1DDict[gG][10].to_pickle( OutFiler, compression='zip' )\n",
    "    OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_G%d_11.pickle\" % (OUT_ROOT, gG) ) )\n",
    "    H1DDict[gG][11].to_pickle( OutFiler, compression='zip' )\n",
    "    OutFiler = os.path.normpath( os.path.join( OUT_DIR, \"%s_H1DPDepth_G%d_12.pickle\" % (OUT_ROOT, gG) ) )\n",
    "    H1DDict[gG][12].to_pickle( OutFiler, compression='zip' )\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
